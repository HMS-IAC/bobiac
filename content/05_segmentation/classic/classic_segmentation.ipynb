{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a60488",
   "metadata": {},
   "source": [
    "# Classic Segmentation\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../notebooks/4_python_basics/Intro_to_Python_II.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/4_python_basics/Intro_to_Python_II.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33553a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.10\"\n",
    "# ///\n",
    "\n",
    "# Standard library imports (no need to declare in dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab370b9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook covers the following steps in building a **classic segmentation pipeline**:\n",
    "\n",
    "| Step | Concept | Why it matters |\n",
    "|---------|---------|----------------|\n",
    "| 0 | Setup | Import necessary packages |\n",
    "| 1 | Loading an Image | Open tif image and display it |\n",
    "| 2 | Filtering | Learn how to process images to improve thresholding results |\n",
    "| 3 | Thresholding | Learn how to use thresholding to generate a binary mask |\n",
    "| 4 | Labeling | Learn how to label binary masks |\n",
    "| 5 | Mask Refinement | Learn how to use watershed segmentation to refine binary masks |\n",
    "| 6 | Processing Many Images | Learn how to apply these processing steps to many images |\n",
    "\n",
    "\n",
    "Each chapter has:\n",
    "\n",
    "1. **Summary** – review core concepts from lecture.\n",
    "2. ✍️ **Exercise** – _your turn_ to write code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c41893",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf93b8",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd7d03",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "We are going to be using existing Python libraries for classic segmentation, so we need to specify them at the beginning of our code. This is called specifying our **dependencies**. It's standard practice to specify all dependencies at the very beginning of your code.\n",
    "\n",
    "For learning purposes, we will import everything here step by step, as it is introduced in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Run the following code block to specify our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# specify dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_closing, remove_small_objects\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d79a7a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf30588",
   "metadata": {},
   "source": [
    "## 1. Loading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5317c0e",
   "metadata": {},
   "source": [
    "**Concept.**\n",
    "To work with an image in Python, we need to specify where the image file is so that we can **read**, or load, it. Once the image file is read, we can **view** it and process it.  \n",
    "\n",
    "### Specifying your file's path\n",
    "Once you have found your file's path, you should assign it to a variable to make it easy to work with. Here's an example:\n",
    "```python\n",
    "file_path = '/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/lectures/classic_segmentation/img.tif'\n",
    "```\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "    <strong>Caution:</strong> Be wary of spaces in folder names, as they sometimes cause terminal to add \\ or / to file directories where they should not be. It is best practice to always use _ in folder names whenever you would have wanted to have a space.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> Specifying file paths is a common task outside of image segmentation with Python, so some of you may have experience with this already. Note the terminology though. An individual file's location is a **path**. A folder's path containing an individual or multiple files is called a **directory**.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2962de",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Specify your image file's path and assign it to the variable `image_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a2b64c",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "image_path = \"../../../_static/images/classic_seg/DAPI_wf_0.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61607421",
   "metadata": {},
   "source": [
    "### Loading an image\n",
    "There are many different ways to read image files in Python. In this lesson, we are using the Python library `tifffile`, to read .tif image files. We will need to import `tifffile` in Setup. We should also import `numpy` to take advantage of accessing np.array tools you have learned about in the previous lesson.\n",
    "\n",
    "| Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| tifffile | Reads and stores tiff files as numpy arrays | `import tifffile` | [tifffile](https://pypi.org/project/tifffile//) |\n",
    "| numpy | Scientific computing package that contains np.arrays | `import numpy as np` | [tifffile](https://numpy.org) |\n",
    "\n",
    "In order to read an image with `tifffile`, we will need to import it, and then provide it with the image's path. We will also import `numpy` too, although it is not necessary for `tifffile` to load the image.\n",
    "```python\n",
    "import tifffile\n",
    "import numpy as np\n",
    "raw_image = tifffile.imread(image_path)\n",
    "```\n",
    "`tifffile.imread()` will use that `image_path` you inputted to find your file and read it. It will then return the read file. Since we will be wanting to work with this file, we assign it to the variable `raw_image` for easy reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14084981",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `tifffile` to read the image and assign it to the variable `raw_image`. Then, print its shape and type \n",
    "Remember to add your imports to Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752d458",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "raw_image = tifffile.imread(image_path)\n",
    "print(raw_image.shape, raw_image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4186f",
   "metadata": {},
   "source": [
    "### Viewing the image\n",
    "In Python, reading the image and viewing it are two separate actions. Now that we have read the image and assigned it to the variable `raw_image`, we can view it using `ndv`, which we will need to import in Setup. \n",
    "\n",
    "| Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| ndv | Multi-dimensional image viewer | `import ndv` | [ndv](https://pypi.org/project/ndv/) |\n",
    "\n",
    "We can use ndv to view `raw_image` as follows: \n",
    "```python\n",
    "ndv.imshow(raw_image)\n",
    "```\n",
    "`ndv.imshow()` will use that `raw_image` you inputted to display your image. It will then return the image displayed in the ndv viewer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c494d",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `ndv` to view the image `raw_image`\n",
    "Remember, we need to import ndv in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7447ab",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff935a",
   "metadata": {},
   "source": [
    "## 2. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517d3d",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Filters** change image pixel values using a **mathematical operation** to smooth and reduce **noise** from images. They can help improve thresholding results. \n",
    "\n",
    "### Applying a filter to an image\n",
    "Here's a summary of the ones we covered in depth in lecture that are good at reducing noise from images: \n",
    "\n",
    "| Filter Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| mean filter | For a given kernel size, sums values in a list and and then divides by the total number of values | `from skimage.filters.rank import mean` | [skimage.filters.rank.mean](https://scikit-image.org/docs/0.25.x/api/skimage.filters.rank.html#skimage.filters.rank.mean) |\n",
    "| Gaussian blur filter | For a given kernel size, multiply each value by a Gaussian profile weighting, then divide by the total number of values | `from skimage.filters import gaussian` | [skimage.filters.gaussian](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) |\n",
    "| median filter | For a given kernel size, take the middle number in a sorted list of numbers | `from skimage.filters import median` | [skimage.filters.median](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.median) |\n",
    "\n",
    "Don't forget to review the documentation to see how to specify the kernel size for each filter!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to apply a Gaussian blur filter to `raw_image` and assign it to the variable `filtered_image`\n",
    "Remember - we need to import the gaussian function from skimage.filters in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "filtered_image = gaussian(raw_image, sigma=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916684f9a58a4a2aa5f864670399430d",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `filtered_image` with `ndv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671c31a24314836a5b85d7ef7fbf015",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0902fd34d4ace834912fa1002cf8e",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa52606d8c4a75a9b52967216f8f3f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40465674",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc95a1a",
   "metadata": {},
   "source": [
    "## 3. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24d030",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Thresholding** is when we select a range of digital values, or **intensity values**, in the image. These selected values are how we define regions of the image we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8902ba",
   "metadata": {},
   "source": [
    "### Defining a threshold\n",
    "We need to define a minimum intensity cutoff which separates the **background** (what we don't care about) from the **foreground** (what we do care about). We can manually pick a an intensity value as this cutoff value like below:\n",
    "```python\n",
    "min_threshold = 50\n",
    "```\n",
    "\n",
    "However, manually changing the value assigned to `min_threshold` until we find an optimal intensity cutoff value is tedious and may vary between images in a dataset. Therefore, it is best practice to instead use established **thresholding algorithms** to automatically define an intensity cutoff value. `skimage.filters` contains many different types of thresholding algorithms, but from that we will be using the Otsu thresholding algorithm `threshold_otsu`. \n",
    "\n",
    "| Thresholding Algorithm | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| Otsu thresholding | Returns threshold using Otsu's method | `from skimage.filters import threshold_otsu` | [threshold_otsu](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.threshold_otsu) |\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> skimage.filters also has a try_all_threshold() function that takes an inputted image and returns a figure comparing the outputs of different thresholding methods. It can be a helpful tool to pick a good thresholding algorithm!\n",
    "</p>\n",
    "\n",
    "We can use `threshold_otsu` from `skimage.filters` as follows: \n",
    "```python\n",
    "threshold = threshold_otsu(filtered_image)\n",
    "```\n",
    "Here, `threshold_otsu()` will use that inputted `filtered_image` to calculate an intensity cutoff value. It will return the cutoff value assigned to the variable `threshold`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to calculate a threshold on `filtered_image` using Otsu's method\n",
    "Remember - we need to import the threshold_otsu function from skimage.filters in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "threshold = threshold_otsu(filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "### Generating a binary mask\n",
    "We now want to use this cutoff value to generate a **binary mask**, which is an image that has only 2 pixel values: one corresponding to the background and one corresponding to the foreground. By generating the binary mask, we will be able to evaluate whether this `threshold` is a sufficient cutoff value. \n",
    "\n",
    "We can generate the binary mask by using *any* comparison operator. Since we want to accept values above a given threshold as foreground, let's use the comparison operator `>`:\n",
    "```python\n",
    "binary_mask = filtered_image > min_threshold\n",
    "```\n",
    "Python will interpret this line of code by going pixel by pixel through `filtered_image` and assigning `True` values where a pixel is greater than `threshold` and assigning `False` values where a pixel is equal or less than `threshold`. The output will be the binary mask image, filled with `True` and `False`. Since this binary mask is something we will be working with, we should assign it a variable, such as `binary_mask`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a79f80",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to threshold `filtered_image` and generate a binary image assigned to the variable `binary_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745cd7aa",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask = filtered_image > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "### Comparing the binary mask to the raw image\n",
    "We can use `matplotlib.pyplot` to view the `raw_image` and `binary_mask` side by side. Plotting 2 images for side by side comparison is a very useful task, so let's package this code into a function:\n",
    "\n",
    "```python\n",
    "#put the code here\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1fa73e5044315a093ec459c9be902",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `raw_image` and `binary_mask` side by side with `matplotlib.pyplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf66aed5cc84ca1b48e60bad68798a8",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce9951d2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71072aba",
   "metadata": {},
   "source": [
    "## 4. Mask Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377aec2",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "Now that we have a binary mask that has white, or value `True`, pixels that match the image foreground and black, or value  `False`, pixels that match the image background, we need a way to distinguish individual objects within this mask. **Labeling** a mask is when we identify individual objects within a binary mask and assign them a unique identifier. \n",
    "\n",
    "### Labeling a binary mask\n",
    "From `skimage.measure` we can use `label()` to label a curated binary mask.\n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `label()` | Label connected regions of an image for Instance segmentation | `from skimage.measure import label` | [threshold_otsu](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label) |\n",
    "\n",
    "Here's how we use `label` from `skimage.measure` to label a binary mask: \n",
    "```python\n",
    "labeled_image = label(binary_mask)\n",
    "```\n",
    "Here, `label()` will take the inputted `binary_mask` and count each connected object in the image and assign them a number starting from 1. It will then return an image where each object's pixels have the value of its object's assigned number. It will return the transformed image, so we should assign it a variable, like `labeled_image`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aed757",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to label `binary_mask` and assign it to the variable `labeled_image`\n",
    "Remember - we need to import the label function from skimage.measure in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced25859",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "labeled_image = label(binary_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c9a12",
   "metadata": {},
   "source": [
    "### Displaying a labeled mask on top of the image\n",
    "Let's now summarize our final segmentation result in 1 image by viewing the `labeled_image` overlaid onto the original `raw_image`. From `skimage.color`, we can use `label2rgb` to do this. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "| `label2rgb()` | Returns an RGB image where color-coded labels are painted over the image | `from skimage.color import label2rgb` | [label2rgb](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb) |\n",
    "\n",
    "Here's how we can use `label2rgb` from `skimage.color` to summarize our segmentation result: \n",
    "```python\n",
    "seg_summary = label2rgb(labeled_image, image = raw_image, bg_label=0)\n",
    "```\n",
    "Here, `label2rgb()` is filled with a few arguments: \n",
    "1. Argument 1: The labeled mask `labeled_image`\n",
    "2. Argument 2: The original image we want the `labeled_image` overlaid onto, specified as `image = raw_image`\n",
    "3. Argument 3: Background transparency of `labeled_image`, which is set to 0 by specifying `bg_label=0` \n",
    "\n",
    "The output will be an rgb image of the labeled mask overlaid onto the raw image. Assign this result a variable for easy reference, like `seg_summary`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa0c30",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that creates an image of `labeled_image` overlaid onto `raw_image` and assign it to the variable `seg_summary`\n",
    "Remember - we need to import the `label2rgb` function from `skimage.color` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21627fd3",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "seg_summary = label2rgb(labeled_image, image=raw_image, bg_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e382214b5f147d187d36a2058b9c724",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: View `seg_summary` with `plt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09d5ef5b5e4bb6ab9b829b10b6a29f",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "source": [
    "How does the segmentation result look? Are all labels corresponding to individual nuclei? If not, additional processing steps are needed to refine `binary_mask`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e582b",
   "metadata": {},
   "source": [
    "## 5. Mask Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e060920",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Mask refinement** is needed when a binary mask still does not accurately match the image foreground. In the context of our nuclei example image, we need to apply additional processing steps to remove connected objects that are too small to be nuclei, fill any holes within nuclei, and separate touching nuclei.\n",
    "\n",
    "### Common mask refinement steps\n",
    "There are many different ways we can refine a binary mask. The table below summarizes the refinement steps we discussed in lecture:\n",
    "\n",
    "| Algorithm Name | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "| Remove Objects by Size | Remove objects smaller than the specified size from the foreground.  | `from skimage.morphology import remove_small_objects` | [skimage.morphology.remove_small_objects](https://scikit-image.org/docs/0.25.x/api/skimage.morphology.html#skimage.morphology.remove_small_objects) |\n",
    "| Morphological Closing | Mathematical operation that results in small hole removal | `from skimage.morphology import binary_closing` | [skimage.morphology.binary_closing](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_closing) |\n",
    "| Watershed Transform | A useful algorithm for separating touching objects. The output is a labeled image. | `from skimage.segmentation import watershed` | [skimage.segmentation.watershed](https://scikit-image.org/docs/0.25.x/api/skimage.segmentation.html#skimage.segmentation.watershed) |\n",
    "\n",
    "Let's now walk through steps to remove objects smaller than nuclei with `remove_small_objects()`, fill in any holes within nuclei with `binary_closing()`, and then separate touching nuclei with `watershed()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "### Removing objects smaller than nuclei\n",
    "In many cases, thresholding will be unsuccessful at rejecting image objects that are debris, as these tend to have high intensity values. However, we can use differences in object size to reject anything that is too small to be a nucleus. \n",
    "\n",
    "From `skimage.morphology` we can use the `remove_small_objects` function, which we already imported in Setup, to remove any connected objects of a specified `min_size`. Here is how we can do that:\n",
    "```python\n",
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "```\n",
    "Here, `remove_small_objects()` will take the inputted `binary_mask` and set any connected object that is smaller than `min_size=10` to have `False` values (in other words, be rejected as foreground). It will then return the updated binary mask, so we should assign it to a variable, such as `binary_mask_sized`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to remove objects smaller than nuclei in `binary_mask` and assign it to the variable `binary_mask_sized`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944c39560714e6e80c856f20744a8e5",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use our plotting function to display `binary_mask` and `binary_masked_sized` side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca27006b894b04b6fc8b79396e2797",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "source": [
    "### Filling holes within nuclei\n",
    "While filtering helps reduce the effect of noise on thresholding, sometimes there will still be areas within an object that are below the minimum threshold value. These areas will show up as holes within a connected object. We can fill these holes by applying a morphological closing operation to the mask. \n",
    "\n",
    "From `skimage.morphology` we can use the `binary_closing` function, which we already imported in Setup, to fill small holes within nuclei. Here is how we can do that:\n",
    "```python\n",
    "binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "```\n",
    "Here, `binary_closing()` will take the inputted `binary_mask_sized` and perform a morphological closing operation optimized for binary images. It will then return the updated binary mask, so we should assign it to a variable, such as `binary_mask_filled`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to fill holes within nuclei in `binary_mask_sized`, and assign the updated mask to the variable `binary_masked_filled`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c27b1587741f2af2001be3712ef0d",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask_filled = binary_closing(binary_mask_sized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffc1ce1c7b4df9ace1bc936b8b1dc2",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use our plotting function to display `binary_mask_sized` and `binary_mask_filled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76127f4a2f6a44fba749ea7800e59d51",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db7b79bc585a40fcaf58bf750017e135",
   "metadata": {},
   "source": [
    "### Separating touching nuclei\n",
    "Let's apply the Watershed Transformation to our `binary_mask` to separate any touching nuclei. From `skimage.segmentation`, we can use `watershed()` to do this. \n",
    "\n",
    "The `watershed()` function needs the following inputs:\n",
    "1. The inverse of the distance transform of the binary mask\n",
    "2. The seeds: labeled image of the peaks of the distance transform\n",
    "3. The binary mask\n",
    "\n",
    "We are going to need a few additional functions to provide the first two inputs to the `watershed()` function. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "| `distance_transform_edt()` | Calculates the distance transform of the input | `from scipy.ndimage import distance_transform_edt` | [scipy.ndimage.distance_transform_edt](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.distance_transform_edt.html) |\n",
    "| `peak_local_max` | Remove objects smaller than the specified size from the foreground.  | `from skimage.feature import peak_local_max` | [skimage.feature.peak_local_max](https://scikit-image.org/docs/0.25.x/api/skimage.feature.html#skimage.feature.peak_local_max) |\n",
    "\n",
    "#### Computing the distance transform\n",
    "We can use the `distance_transform_edt()` function from `scipy.ndimage` to get the distance transform of our refined binary_mask `binary_mask_filled`:\n",
    "```python\n",
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to calculate the distance transform of `binary_mask_filled` and assign it to the variable `distance_transform`\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3efd5258a48a79c179ea5c6759f01",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bc0b9dd2c44919cc8dcca39b469f8",
   "metadata": {},
   "source": [
    "#### Creating seeds for Watershed\n",
    "Once we have the distance transform of `binary_mask_filled`, we can use the `peak_local_max()` function from `skimage.feature` to get local maxima values from the distance transform. However, we want to make sure that we get only 1 local maximum per object. We therefore can apply a `footprint` input confine a region the `peak_local_max` function will look for local maxima. Doing so will constrain how many maxima the function returns. We can also specify a `min_distance` separating peaks, which will also help constrain the number of maxima to be 1 per nucleus. \n",
    "\n",
    "Here's how we would write the code:\n",
    "``` python\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(distance_transform, footprint=np.ones((25, 25)), min_distance=10)\n",
    "```\n",
    "\n",
    "Now that we have the maxima, we need to organize them for the `watershed()` function as a labeled image. We can do that by creating a binary image from the local maxima coordinates and then labeling the mask:\n",
    "```python\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50416e276a0479cbe66534ed1713a40",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that uses `distance_transform` to create seeds for the Watershed algorithm. Assign the seeds to the variable `seeds`.\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a27a456b804aa2a380d5edf15a5daf",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(\n",
    "    distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    ")\n",
    "\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61877af4e7f4313ad8234302950b331",
   "metadata": {},
   "source": [
    "#### Applying the Watershed Transform\n",
    "Now we have everything we need to input into the `watershed()` function:\n",
    "1. The inverse of the distance transform of the binary mask: `-distance_transform`\n",
    "2. The seeds: `seeds`\n",
    "3. The binary mask: `binary_mask_filled`\n",
    "\n",
    "We can now call the Watershed function as follows:\n",
    "``` python\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "```\n",
    "\n",
    "Here, `watershed()` will apply the Watershed Transform to the inputted `binary_image_filled`. It will return the transformed, **labeled** image. We assign it to the variable `labeled_ws_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd599b",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code to apply a watershed transform to `binary_mask_filled` and assign it to the variable `labeled_ws_image`\n",
    "Remember to import what you need in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e822bc",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff116bae5b45f6b6dae177083008cf",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write code that creates an image of `labeled_ws_image` overlaid onto `raw_image` and assign it to the variable `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075f00cfa8d463f84130041b1e44ca7",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "seg_summary_refined = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abde8c5d2e435093904b13db685a53",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Use `plt` to display `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20a2a0e21149b5b06860e930401eb5",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "plt.imshow(seg_summary_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "## END OF FIRST LAB SECTION - STOP HERE FOR LAST LECTURE COMPONENT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcb4dd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 6. Processing Many Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "Statistically relevant & reproducible measurements come from analyzing many fluorescence images. Therefore, we need to adapt our code to efficiently run on many images, not just 1 at a time! We can do so by implementing a `for` loop and the `Path` function to our image path handling. We also want to add the ability to save output files using `tifffile.imwrite()`.\n",
    "\n",
    "### Consolidate code for image processing steps\n",
    "The first step to processing many images is to write code to process a single image, just as we have done above in the previous sections. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d5ab97d17b4c38ab41a2b065bbd0c0",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Copy and paste all of the code we wrote in the above sections to load and segment our single nucleus image\n",
    "\n",
    "Remember, we want code that does the following steps: \n",
    "* Specify dependencies\n",
    "* Load the image\n",
    "* Filter the image with a Gaussian filter\n",
    "* Threshold to generate a binary mask\n",
    "* Refine the mask: Remove small objects\n",
    "* Refine the mask: Fill small  holes\n",
    "* Refine the mask: Watershed\n",
    "* Review our final segmentation summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903197826d2e44dfa0208e8f97c69327",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# specify dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_closing, remove_small_objects\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "# load the image\n",
    "image_path = \"../../../_static/images/classic_seg/DAPI_wf_0.tif\"\n",
    "raw_image = tifffile.imread(image_path)\n",
    "\n",
    "# filter the image with gaussian filter\n",
    "filtered_image = gaussian(raw_image, sigma=1)\n",
    "\n",
    "# threshold filtered_image to generate binary mask\n",
    "binary_mask = filtered_image > threshold_otsu(filtered_image)\n",
    "\n",
    "# Remove small objects\n",
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "\n",
    "# Fill small holes by performing morphological closing\n",
    "binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "\n",
    "# apply watershed to separate nuclei and label mask\n",
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(\n",
    "    distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    ")\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "\n",
    "# visualize the segmentation result\n",
    "seg_summary_refined = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)\n",
    "plt.imshow(seg_summary_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015066fb96f841e5be1e03a9eaadc3b6",
   "metadata": {},
   "source": [
    "### Using a for loop to loop through image paths\n",
    "Now that we have the code in one place, we need to adapt it to be able to process more than one image. We can do that by looping through image file paths. From `pathlib`, we can use `Path` in conjunction with a `for` loop to iterate through many image file paths. Here's how we would write the code to do that:\n",
    "```python\n",
    "from pathlib import Path\n",
    "folder_path = Path(“/Users/edelase/bobiac/”) # update with your folder's path\n",
    "for image_path in folder_path.iterdir():\n",
    "    # do things\n",
    "```\n",
    "\n",
    "Here, Python is doing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c31777baf4441b988909d29205560c",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write a for loop that prints all image file paths in a folder using `Path` and `iterdir()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734001bcbac423990a4356310d8df13",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(\n",
    "    \"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\"\n",
    ")\n",
    "for image_path in folder_path.iterdir():\n",
    "    print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27531e93873647d9a5bf1112f2051a59",
   "metadata": {},
   "source": [
    "### Using glob to loop through only tif image paths\n",
    "What if we have more than just tif images in our folder? Instead of using `iterdir()`, we can selectively loop through files ending with \".tif\" using `glob`. Here's how we would write the code to do that:\n",
    "```python\n",
    "import glob\n",
    "from pathlib import Path\n",
    "folder_path = Path(\"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\")\n",
    "for image_path in folder_path.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    # do things\n",
    "```\n",
    "\n",
    "Here, Python is doing..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3041e9ffdb2416ea2009d3a6a4c5716",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Write a for loop that prints all tif image file paths in a folder using `Path` and `glob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae71b6e24e4355a139fb9fe2e09b64",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "folder_path = Path(\n",
    "    \"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\"\n",
    ")\n",
    "for image_path in folder_path.glob(\"*.tif\"):  # only loop through files ending in .tif\n",
    "    print(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141936c6c8a4c478a75aea4ff665469",
   "metadata": {},
   "source": [
    "### Using a for loop to process many images\n",
    "Now that we have learned how to loop through image paths efficiently, we can now apply this concept to increase the throughput of our classic segmentation processing code. We can do that by putting each processing step, starting with reading the image, within the for loop. \n",
    "\n",
    "```python\n",
    "folder_path = Path(\"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\")\n",
    "for image_path in folder_path.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    # load the image\n",
    "    raw_image = tifffile.imread(image_path)\n",
    "    ...\n",
    "    break # Use for troubleshooting! Only do first loop until confident you're ready to loop through all files\n",
    "```\n",
    "\n",
    "Python will do the following..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c096f4dcf400fbdceb075ef31fca3",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Improve your classic segmentation code above by adding a for loop to process many images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427a666a1b549ef9b573d6f946bfc3b",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_closing, remove_small_objects\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "folder_path = Path(\n",
    "    \"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\"\n",
    ")\n",
    "for image_path in folder_path.glob(\"*.tif\"):  # only loop through files ending in .tif\n",
    "    # load the image\n",
    "    raw_image = tifffile.imread(image_path)\n",
    "\n",
    "    # filter the image with gaussian filter\n",
    "    filtered_image = gaussian(raw_image, sigma=1)\n",
    "\n",
    "    # threshold filtered_image to generate binary mask\n",
    "    binary_mask = filtered_image > threshold_otsu(filtered_image)\n",
    "\n",
    "    # Remove small objects\n",
    "    binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "\n",
    "    # Fill small holes by performing morphological closing\n",
    "    binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "\n",
    "    # apply watershed to separate nuclei and label mask\n",
    "    # compute the distance transform\n",
    "    distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "    # find local maxima coordinates in the distance transform\n",
    "    local_maxima_coords = peak_local_max(\n",
    "        distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    "    )\n",
    "    # create a binary image from the local maxima coordinates\n",
    "    local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "    local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "    # use the local maxima to create seeds for the watershed algorithm\n",
    "    seeds = label(local_maxima)\n",
    "    # apply the watershed algorithm to segment the image and get labels\n",
    "    labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "\n",
    "    # visualize the segmentation result\n",
    "    seg_summary_refined = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310869696a145bf841235dd6c036af8",
   "metadata": {},
   "source": [
    "### Saving Output Files\n",
    "Now that we have our for loop set up, we can modify our code to save the `labeled_ws_image` as an outputted tif file. We can do this using `tifffile.imwrite()`:\n",
    "\n",
    "```python\n",
    "tifffile.imwrite(\"output_image.tif\", labeled_ws_image.astype(\"uint32\"))\n",
    "```\n",
    "\n",
    "Here, Python is doing the following..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f166d9f0ce4939b04b8e9245f75c27",
   "metadata": {},
   "source": [
    "<p class=\"alert alert-info\">\n",
    "    <strong>NOTE:</strong> The <i>dtype</i> of the labels image is important because will determine the maximum number of labels that can be stored in the image. In fact, in a label image, each object is assigned a unique integer label, and the <i>dtype</i> determines the range of integers that can be used for labeling (e.g. <i>uint8</i> -> max 255 objects).\n",
    "    <br>\n",
    "    By default, the labels generated by the `skimage.measure.label` function are of type <i>uint32</i>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c10029e1707434ab3fe295caea7d13f",
   "metadata": {},
   "source": [
    "We can't just directly write, or *hard code*, a file name for the image we are trying to save because it will be different for each iteration of our for loop. Therefore, we need a better way to automatically generate a file name for each loop. We can do this using `stem`. \n",
    "\n",
    "```python\n",
    "folder_path = Path(\"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\")\n",
    "for image_path in folder_path.glob(\"*.tif\"): # only loop through files ending in .tif\n",
    "    image_path.stem # file name, without .tif at the end\n",
    "```\n",
    "Here, Python..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f0888c55a4478ace3eac39384dff4",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Print the file name of each tif image in your folder using `stem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94f5a17fa734d288763e7d9a3758173",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "folder_path = Path(\n",
    "    \"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\"\n",
    ")\n",
    "for image_path in folder_path.glob(\"*.tif\"):  # only loop through files ending in .tif\n",
    "    print(image_path.stem)  # file name, without .tif at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b839107204e409e0496d3d944026c",
   "metadata": {},
   "source": [
    "Now, let's apply these concepts to our segmentation code so that we can save each final labeled image as an outputted tif file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981b37c798e44f684168605b9db02c6",
   "metadata": {},
   "source": [
    "### ✍️ Exercise: Modify your classic segmentation code that processes many images to save each `labeled_ws_image`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1800d1c114147a536b8aa907907c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_closing, remove_small_objects\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "input_dir = Path(\n",
    "    \"/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/_static/images/classic_seg/\"\n",
    ")\n",
    "output_dir = Path(\"\")\n",
    "for image_path in folder_path.glob(\"*.tif\"):  # only loop through files ending in .tif\n",
    "    # load the image\n",
    "    raw_image = tifffile.imread(image_path)\n",
    "\n",
    "    # filter the image with gaussian filter\n",
    "    filtered_image = gaussian(raw_image, sigma=1)\n",
    "\n",
    "    # threshold filtered_image to generate binary mask\n",
    "    binary_mask = filtered_image > threshold_otsu(filtered_image)\n",
    "\n",
    "    # Remove small objects\n",
    "    binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "\n",
    "    # Fill small holes by performing morphological closing\n",
    "    binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "\n",
    "    # apply watershed to separate nuclei and label mask\n",
    "    # compute the distance transform\n",
    "    distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "    # find local maxima coordinates in the distance transform\n",
    "    local_maxima_coords = peak_local_max(\n",
    "        distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    "    )\n",
    "    # create a binary image from the local maxima coordinates\n",
    "    local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "    local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "    # use the local maxima to create seeds for the watershed algorithm\n",
    "    seeds = label(local_maxima)\n",
    "    # apply the watershed algorithm to segment the image and get labels\n",
    "    labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "\n",
    "    # visualize the segmentation result\n",
    "    seg_summary_refined = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)\n",
    "\n",
    "    # save labeled_ws_image\n",
    "    output_filename = output_dir / f\"{image_path.stem}_labels.tif\"\n",
    "    tifffile.imwrite(output_filename, labeled_ws_image.astype(\"uint32\"))\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
