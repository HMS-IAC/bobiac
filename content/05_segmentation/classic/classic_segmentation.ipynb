{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a60488",
   "metadata": {},
   "source": [
    "# Classic Segmentation\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../notebooks/4_python_basics/Intro_to_Python_II.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/4_python_basics/Intro_to_Python_II.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f33553a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.10\"\n",
    "# ///\n",
    "\n",
    "# Standard library imports (no need to declare in dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab370b9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook covers the following steps in building a **classic segmentation pipeline**:\n",
    "\n",
    "| Step | Concept | Why it matters |\n",
    "|---------|---------|----------------|\n",
    "|¬†0 | Setup | Import necessary packages |\n",
    "| 1 | Loading an Image | Open tif image and display it |\n",
    "| 2 | Filtering | Learn how to process images to improve thresholding results |\n",
    "|¬†3 | Thresholding | Learn how to use thresholding to generate a binary mask |\n",
    "| 4 | Labeling | Learn how to label binary masks |\n",
    "| 5 | Mask Refinement | Learn how to use watershed segmentation to refine binary masks |\n",
    "| 6 | Processing Many Images | Learn how to apply these processing steps to many images |\n",
    "\n",
    "\n",
    "Each chapter has:\n",
    "\n",
    "1. **Summary** ‚Äì review core concepts from lecture.\n",
    "2. ‚úçÔ∏è **Exercise** ‚Äì _your turn_ to write code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c41893",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf93b8",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd7d03",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "We are going to be using existing Python packages for classic segmentation, so we need to specify them at the beginning of our code. This is called specifying our **dependencies**. It's standard practice to specify all dependencies at the very beginning of your code.\n",
    "\n",
    "For learning purposes, we will import everything here step by step, as it is introduced in the following chapters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code block to specify our dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# specify dependencies\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.color import label2rgb\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.measure import label\n",
    "from skimage.morphology import binary_closing, remove_small_objects\n",
    "from skimage.segmentation import watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d79a7a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf30588",
   "metadata": {},
   "source": [
    "## 1. Loading an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5317c0e",
   "metadata": {},
   "source": [
    "**Concept.**\n",
    "To work with an image in Python, we need to specify where the image file is so that we can **read**, or load, it. Once the image file is read, we can **view** it and process it.  \n",
    "\n",
    "### Specifying your file's path\n",
    "Once you have found your file's path, you should assign it to a variable to make it easy to work with. Here's an example:\n",
    "```python\n",
    "file_path = '/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/lectures/classic_segmentation/img.tif'\n",
    "```\n",
    "\n",
    "**‚ùóÔ∏èCAUTION‚ùóÔ∏è** Be wary of spaces in folder names, as they sometimes cause terminal to add `\\` or `/` to file directories where they should not be. It is best practice to always use `_` in folder names whenever you would have wanted to have a space.\n",
    "\n",
    "**üóíÔ∏è NOTE:** Specifying file paths is a common task outside of image segmentation with Python, so some of you may have experience with this already. Note the terminology though. An individual file's location is a **path**. A folder's path containing an individual or multiple files is called a **directory**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2962de",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Specify your image file's path and assign it to the variable `image_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a2b64c",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "image_path = \"../../../_static/images/classic_seg/DAPI_wf_0.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61607421",
   "metadata": {},
   "source": [
    "### Reading an image\n",
    "There are many different ways to read image files in Python. In this lesson, we are using the Python package `tifffile`, to read .tif image files. In order to read an image with `tifffile`, we will need to import it, and then provide it with the image's path:\n",
    "```python\n",
    "import tifffile # add this to 0. Setup code block\n",
    "raw_image = tifffile.imread(image_path)\n",
    "```\n",
    "`tifffile.imread()` will use that `image_path` you inputted to find your file and read it. It will then return the read file. Since we will be wanting to work with this file, we assign it to the variable `raw_image` for easy reference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14084981",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code to read the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f752d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 2304) float32\n"
     ]
    }
   ],
   "source": [
    "raw_image = tifffile.imread(image_path)\n",
    "print(raw_image.shape, raw_image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae4186f",
   "metadata": {},
   "source": [
    "### Viewing the image\n",
    "In Python, reading the image and viewing it are two separate actions. Now that we have read the image and assigned it to the variable `raw_image`, we can view it using `ndv`, which we will need to import in Setup. \n",
    "\n",
    "| Package Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "|¬†ndv | Multi-dimensional image viewer | `import ndv` | [ndv](https://pypi.org/project/ndv/) |\n",
    "\n",
    "We can use ndv to view `raw_image` as follows: \n",
    "```python\n",
    "ndv.imshow(raw_image)\n",
    "```\n",
    "`ndv.imshow()` will use that `raw_image` you inputted to display your image. It will then return the image displayed in the ndv viewer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c494d",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code to view the image with `ndv`\n",
    "Remember, we need to import ndv in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7447ab",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c804e27f84196a10c8828c723f798",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(raw_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb2a444614c0babb325280ed9130a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff935a",
   "metadata": {},
   "source": [
    "## 2. Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517d3d",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Filters** change image pixel values using a **mathematical operation** to smooth and reduce **noise** from images. They can help improve thresholding results. \n",
    "\n",
    "### Applying a filter to an image\n",
    "There are many different filters we can apply. Here's a summary of the ones we covered in depth in lecture: \n",
    "\n",
    "| Filter Name | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "|¬†mean filter | For a given kernel size, sums values in a list and and then divides by the total number of values | `from skimage.filters.rank import mean` | [skimage.filters.rank.mean](https://scikit-image.org/docs/0.25.x/api/skimage.filters.rank.html#skimage.filters.rank.mean) |\n",
    "| Gaussian blur filter | For a given kernel size, multiply each value by a Gaussian profile weighting, then divide by the total number of values | `from skimage.filters import gaussian` | [skimmage.filters.gaussian](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian) |\n",
    "|¬†median filter | For a given kernel size, take the middle number in a sorted list of numbers | `from skimage.filters import median` | [skimage.filters.median](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.median) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to apply a Gaussian blur filter to `raw_image` and assign it to the variable `filtered_image`\n",
    "Remember - we need to import the gaussian function from skimage.filters in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "filtered_image = gaussian(raw_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916684f9a58a4a2aa5f864670399430d",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code to view `filtered_image` with `ndv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1671c31a24314836a5b85d7ef7fbf015",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0902fd34d4ace834912fa1002cf8e",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(filtered_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fa52606d8c4a75a9b52967216f8f3f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40465674",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc95a1a",
   "metadata": {},
   "source": [
    "## 3. Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24d030",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Thresholding** is when we select a range of digital values, or **intensity values**, in the image. These selected values are how we define regions of the image we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8902ba",
   "metadata": {},
   "source": [
    "### Defining a threshold\n",
    "We need to define a minimum intensity cutoff which separates the **background** (what we don't care about) from the **foreground** (what we do care about). We can manually pick a an intensity value as this cutoff value like below:\n",
    "```python\n",
    "min_threshold = 50\n",
    "```\n",
    "\n",
    "However, manually changing the value assigned to `min_threshold` until we find an optimal intensity cutoff value is tedious and may vary between images in a dataset. Therefore, it is best practice to instead use established **thresholding algorithms** to automatically define an intensity cutoff value. `skimage.filters` contains many different types of thresholding algorithms, but from that we will be using the Otsu thresholding algorithm `threshold_otsu`. \n",
    "\n",
    "| Thresholding Algorithm | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "|¬†Otsu thresholding | Returns threshold using Otsu's method | `from skimage.filters import threshold_otsu` | [threshold_otsu](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.threshold_otsu) |\n",
    "\n",
    "We can use `threshold_otsu` from `skimage.filters` as follows: \n",
    "```python\n",
    "min_threshold = threshold_otsu(filtered_image)\n",
    "```\n",
    "Here, `threshold_otsu()` will use that inputted `filtered_image` to calculate an intensity cutoff value. It will return the cutoff value assigned to the variable `min_threshold`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bbdb311c014d738909a11f9e486628",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to calculate a threshold on `filtered_image` using Otsu's method\n",
    "Remember - we need to import the threshold_otsu function from skimage.filters in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43b363d81ae4b689946ece5c682cd59",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "min_threshold = threshold_otsu(filtered_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a65eabff63a45729fe45fb5ade58bdc",
   "metadata": {},
   "source": [
    "### Generating a binary mask\n",
    "We now want to use this cutoff value to generate a **binary mask**, which is an image that has only 2 pixel values: one corresponding to the background and one corresponding to the foreground. By generating the binary mask, we will be able to evaluate whether this `min_threshold` is a sufficient cutoff value. \n",
    "\n",
    "We can generate the binary mask by using the comparison operator `>`:\n",
    "```python\n",
    "binary_mask = filtered_image > min_threshold\n",
    "```\n",
    "Python will interpret this line of code by going pixel by pixel through `filtered_image` and assigning `True` values where a pixel is greater than `min_threshold` and assigning `False` values where a pixel is equal or less than `min_threshold`. The output will be the binary mask image, filled with `True` and `False`. Since this binary mask is something we will be working with, we should assign it a variable, such as `binary_mask`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a79f80",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to threshold `filtered_image` and generate a binary image assigned to the variable `binary_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745cd7aa",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask = filtered_image > min_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a1fa73e5044315a093ec459c9be902",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code to view `binary_mask` with `ndv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf66aed5cc84ca1b48e60bad68798a8",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3efd5258a48a79c179ea5c6759f01",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bc0b9dd2c44919cc8dcca39b469f8",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9951d2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71072aba",
   "metadata": {},
   "source": [
    "## 4. Mask Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4377aec2",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "Now that we have a binary mask that has white, or value `True`, pixels that match the image foreground and black, or value  `False`, pixels that match the image background, we need a way to distinguish individual objects within this mask. **Labeling** a mask is when we identify individual objects within a binary mask and assign them a unique identifier. \n",
    "\n",
    "### Labeling a binary mask\n",
    "From `skimage.measure` we can use `label()` to label a curated binary mask.\n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "|¬†`label()` | Label connected regions of an image for Instance segmentation | `from skimage.measure import label` | [threshold_otsu](https://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label) |\n",
    "\n",
    "Here's how we use `label` from `skimage.measure` to label a binary mask: \n",
    "```python\n",
    "labeled_image = label(binary_mask)\n",
    "```\n",
    "Here, `label()` will take the inputted `binary_mask` and count each connected object in the image and assign them a number starting from 1. It will then return an image where each object's pixels have the value of its object's assigned number. It will return the transformed image, so we should assign it a variable, like `labeled_image`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aed757",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to label `binary_mask` and assign it to the variable `labeled_image`\n",
    "Remember - we need to import the label function from skimage.measure in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ced25859",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "labeled_image = label(binary_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584c9a12",
   "metadata": {},
   "source": [
    "### Displaying a labeled mask on top of the image\n",
    "Let's now summarize our final segmentation result in 1 image by viewing the `labeled_image` overlaid onto the original `raw_image`. From `skimage.color`, we can use `label2rgb` to do this. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link | \n",
    "|---------|---------|----------------| ----------------|\n",
    "|¬†`label2rgb()` | Returns an RGB image where color-coded labels are painted over the image | `from skimage.color import label2rgb` | [label2rgb](https://scikit-image.org/docs/dev/api/skimage.color.html#skimage.color.label2rgb) |\n",
    "\n",
    "Here's how we can use `label2rgb` from `skimage.color` to summarize our segmentation result: \n",
    "```python\n",
    "seg_summary = label2rgb(labeled_image, image = raw_image, bg_label=0)\n",
    "```\n",
    "Here, `label2rgb()` is filled with a few arguments: \n",
    "1. Argument 1: The labeled mask `labeled_image`\n",
    "2. Argument 2: The original image we want the `labeled_image` overlaid onto, specified as `image = raw_image`\n",
    "3. Argument 3: Background transparency of `labeled_image`, which is set to 0 by specifying `bg_label=0` \n",
    "\n",
    "The output will be an rgb image of the labeled mask overlaid onto the raw image. Assign this result a variable for easy reference, like `seg_summary`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aa0c30",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code that creates an image of `labeled_image` overlaid onto `raw_image` and assign it to the variable `seg_summary`\n",
    "Remember - we need to import the `label2rgb` function from `skimage.color` in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21627fd3",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edelase/HMS Dropbox/Eva de la Serna/Eva_CITE_folder/projects/bobiac/git/bobiac/.venv/lib/python3.12/site-packages/skimage/color/colorlabel.py:149: UserWarning: Negative intensities in `image` are not supported\n",
      "  rgb = _label2rgb_overlay(\n"
     ]
    }
   ],
   "source": [
    "seg_summary = label2rgb(labeled_image, image=raw_image, bg_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e382214b5f147d187d36a2058b9c724",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the following code to view `seg_summary` with `ndv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b09d5ef5b5e4bb6ab9b829b10b6a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndv.imshow(seg_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50416e276a0479cbe66534ed1713a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(seg_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a27a456b804aa2a380d5edf15a5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3933fab20d04ec698c2621248eb3be0",
   "metadata": {},
   "source": [
    "How does the segmentation result look? Are all labels corresponding to individual nuclei? If not, additional processing steps are needed to refine `binary_mask`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e582b",
   "metadata": {},
   "source": [
    "## 5. Mask Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e060920",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "**Mask refinement** is needed when a binary mask still does not accurately match the image foreground. In the context of our nuclei example image, we need to apply additional processing steps to remove connected objects that are too small to be nuclei, fill any holes within nuclei, and separate touching nuclei.\n",
    "\n",
    "### Common mask refinement steps\n",
    "There are many different ways we can refine a binary mask. The table below summarizes very common refinement steps:\n",
    "\n",
    "| Algorithm Name | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "|¬†Watershed Transform | A useful algorithm for separating touching objects. The output is a labeled image. | `from skimage.segmentation import watershed` | [skimage.segmentation.watershed](https://scikit-image.org/docs/0.25.x/api/skimage.segmentation.html#skimage.segmentation.watershed) |\n",
    "|¬†Remove Objects by Size | Remove objects smaller than the specified size from the foreground.  | `from skimage.morphology import remove_small_objects` | [skimage.morphology.remove_small_objects](https://scikit-image.org/docs/0.25.x/api/skimage.morphology.html#skimage.morphology.remove_small_objects) |\n",
    "| Morphological Opening | Mathematical operation that results in small object removal | `from skimage.morphology import binary_opening` | [skimage.morphology.binary_opening](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_opening) |\n",
    "|¬†Morphological Closing | Mathematical operation that results in small hole removal | `from skimage.morphology import binary_closing` | [skimage.morphology.binary_closing](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_closing) |\n",
    "| Morphological Erosion | Mathematical operation that reduces shape size | `from skimage.morphology import binary_erosion` | [skimage.morphology.binary_erosion](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_erosion) |\n",
    "| Morphological Dilation | Mathematical operation that increases shape size | `from skimage.morphology import binary_dilation` | [skimage.morphology.binary_dilation](https://scikit-image.org/docs/stable/api/skimage.morphology.html#skimage.morphology.binary_dilation) |\n",
    "\n",
    "Let's now walk through steps to remove objects smaller than nuclei with `remove_small_objects()`, fill in any holes within nuclei with `binary_closing()`, and then separate touching nuclei with `watershed()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4641cc4064e0191573fe9c69df29b",
   "metadata": {},
   "source": [
    "### Removing objects smaller than nuclei\n",
    "In many cases, thresholding will be unsuccessful at rejecting image objects that are debris, as these tend to have high intensity values. However, we can use differences in object size to reject anything that is too small to be a nucleus. \n",
    "\n",
    "From `skimage.morphology` we can use the `remove_small_objects` function, which we already imported in Setup, to remove any connected objects of a specified `min_size`. Here is how we can do that:\n",
    "```python\n",
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "```\n",
    "Here, `remove_small_objects()` will take the inputted `binary_mask` and set any connected object that is smaller than `min_size=10` to have `False` values (in other words, be rejected as foreground). It will then return the updated binary mask, so we should assign it to a variable, such as `binary_mask_sized`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309879909854d7188b41380fd92a7c3",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to remove objects smaller than nuclei in `binary_mask` and assign it to the variable `binary_mask_sized`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed186c9a28b402fb0bc4494df01f08d",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1944c39560714e6e80c856f20744a8e5",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the code below to use `ndv` to display `binary_masked_sized`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca27006b894b04b6fc8b79396e2797",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(binary_mask_sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61877af4e7f4313ad8234302950b331",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(binary_mask_sized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5ab97d17b4c38ab41a2b065bbd0c0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1e1581032b452c9409d6c6813c49d1",
   "metadata": {},
   "source": [
    "### Filling holes within nuclei\n",
    "While filtering helps reduce the effect of noise on thresholding, sometimes there will still be areas within an object that are below the minimum threshold value. These areas will show up as holes within a connected object. We can fill these holes by applying a morphological closing operation to the mask. \n",
    "\n",
    "From `skimage.morphology` we can use the `binary_closing` function, which we already imported in Setup, to fill small holes within nuclei. Here is how we can do that:\n",
    "```python\n",
    "binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "```\n",
    "Here, `binary_closing()` will take the inputted `binary_mask_sized` and perform a morphological closing operation optimized for binary images. It will then return the updated binary mask, so we should assign it to a variable, such as `binary_mask_filled`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379cbbc1e968416e875cc15c1202d7eb",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to fill holes within nuclei in `binary_mask_sized`, and assign the updated mask to the variable `binary_masked_filled`\n",
    "Remember, we need to import functions we want to use in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c27b1587741f2af2001be3712ef0d",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "binary_mask_filled = binary_closing(binary_mask_sized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ffc1ce1c7b4df9ace1bc936b8b1dc2",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the code below to use `ndv` to display `binary_masked_filled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76127f4a2f6a44fba749ea7800e59d51",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(binary_mask_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903197826d2e44dfa0208e8f97c69327",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(binary_mask_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015066fb96f841e5be1e03a9eaadc3b6",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b79bc585a40fcaf58bf750017e135",
   "metadata": {},
   "source": [
    "### Separating touching nuclei\n",
    "Let's apply the Watershed Transformation to our `binary_mask` to separate any touching nuclei. From `skimage.segmentation`, we can use `watershed()` to do this. \n",
    "\n",
    "The `watershed()` function needs the following inputs:\n",
    "1. The inverse of the distance transform of the binary mask\n",
    "2. The seeds: labeled image of the peaks of the distance transform\n",
    "3. The binary mask\n",
    "\n",
    "We are going to need a few additional functions to provide the first two inputs to the `watershed()` function. \n",
    "\n",
    "| Function | Description | How to import it | Documentation Link |\n",
    "|---------|---------|----------------|----------------|\n",
    "|¬†`distance_transform_edt()` | Calculates the distance transform of the input | `from scipy.ndimage import distance_transform_edt` | [scipy.ndimage.distance_transform_edt](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.distance_transform_edt.html) |\n",
    "|¬†`peak_local_max` | Remove objects smaller than the specified size from the foreground.  | `from skimage.feature import peak_local_max` | [skimage.feature.peak_local_max](https://scikit-image.org/docs/0.25.x/api/skimage.feature.html#skimage.feature.peak_local_max) |\n",
    "\n",
    "#### Computing the distance transform\n",
    "We can use the `distance_transform_edt()` function from `scipy.ndimage` to get the distance transform of our refined binary_mask `binary_mask_filled`:\n",
    "```python\n",
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "```\n",
    "\n",
    "#### Finding the coordinates of peaks in the distance transform\n",
    "Once we have the distance transform of `binary_mask_filled`, we can use the `peak_local_max()` function from `skimage.feature` to get local maxima values from the distance transform. However, we want to make sure that we get only 1 local maximum per object. We therefore can apply a `footprint` input confine a region the `peak_local_max` function will look for local maxima. Doing so will constrain how many maxima the function returns. We can also specify a `min_distance` separating peaks, which will also help constrain the number of maxima to be 1 per nucleus. \n",
    "\n",
    "Here's how we would write the code:\n",
    "``` python\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(distance, footprint=np.ones((25, 25)), min_distance=10)\n",
    "```\n",
    "\n",
    "Now that we have the maxima, we need to organize them for the `watershed()` function as a labeled image. We can do that by creating a binary image from the local maxima coordinates and then labeling the mask:\n",
    "```python\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)\n",
    "```\n",
    "\n",
    "#### Applying the Watershed Transform\n",
    "\n",
    "``` python\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "```\n",
    "\n",
    "Here, `watershed()` will apply the Watershed Transform to the inputted `binary_image_filled`. It will return the transformed, labeled image, so we should assign it a variable, such as `labeled_ws_image`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd599b",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code to apply a watershed transform to `binary_mask_filled` and assign it to the variable `labeled_ws_image`\n",
    "Remember, all packages have already been imported in Setup!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e822bc",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(\n",
    "    distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    ")\n",
    "\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)\n",
    "\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff116bae5b45f6b6dae177083008cf",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Write code that creates an image of `labeled_ws_image` overlaid onto `raw_image` and assign it to the variable `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9075f00cfa8d463f84130041b1e44ca7",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "seg_summary_refined = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abde8c5d2e435093904b13db685a53",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Run the code below to use `ndv` to display `seg_summary_refined`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e20a2a0e21149b5b06860e930401eb5",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "ndv.imshow(seg_summary_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c31777baf4441b988909d29205560c",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(seg_summary_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5734001bcbac423990a4356310d8df13",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ea5561624da68c537baed56e602f",
   "metadata": {},
   "source": [
    "## END OF FIRST LAB SECTION - STOP HERE FOR LAST LECTURE COMPONENT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcb4dd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {},
   "source": [
    "## 6. Processing Many Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {},
   "source": [
    "**Concept.**  \n",
    "Statistically relevant & reproducible measurements come from analyzing many fluorescence images. Therefore, we need to adapt our code to efficiently run on many images, not just 1 at a time! We can do so by implementing a `for` loop and the `Path` function to our image path handling. \n",
    "\n",
    "### Using a for loop to apply processing steps to many images\n",
    "From `pathlib`, we can use `Path` in conjunction with a `for` loop to iterate through many image file paths. Here's how we would write the code to do that:\n",
    "```python\n",
    "from pathlib import Path\n",
    "folder_path = Path(‚Äú/Users/edelase/bobiac‚Äù) # update with your folder's path\n",
    "for image_path in path.iterdir():\n",
    "    # do our classic segmentation processing steps\n",
    "```\n",
    "\n",
    "### Decomposing our processing steps into functions\n",
    "We could just copy paste the lines of code that we wrote in the exercises above one after another within a `for` loop, but a better strategy would be to organize the code for each processing step into its own function. Doing so will make each step easier to reuse in future code you write or share with collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {},
   "source": [
    "### ‚úçÔ∏è Exercise: Improve the code below! \n",
    "1. Group processing steps into functions\n",
    "2. Add a for loop so processing steps can be applied to many images\n",
    "\n",
    "- load an image from ...\n",
    "- filter image\n",
    "- generate the ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify dependencies\n",
    "\n",
    "# load the image\n",
    "image_path = \"\"\n",
    "raw_image = tifffile.imread(image_path)\n",
    "\n",
    "# filter the image with gaussian filter\n",
    "filtered_image = gaussian(raw_image)\n",
    "\n",
    "# threshold filtered_image to generate binary mask\n",
    "binary_mask = filtered_image > threshold_otsu(filtered_image)\n",
    "\n",
    "# Remove small objects\n",
    "binary_mask_sized = remove_small_objects(binary_mask, min_size=10)\n",
    "\n",
    "# Fill small holes by performing morphological closing\n",
    "binary_mask_filled = binary_closing(binary_mask_sized)\n",
    "\n",
    "# apply watershed to separate nuclei and label mask\n",
    "# compute the distance transform\n",
    "distance_transform = distance_transform_edt(binary_mask_filled)\n",
    "# find local maxima coordinates in the distance transform\n",
    "local_maxima_coords = peak_local_max(\n",
    "    distance_transform, footprint=np.ones((25, 25)), min_distance=10\n",
    ")\n",
    "# create a binary image from the local maxima coordinates\n",
    "local_maxima = np.zeros_like(binary_mask_filled, dtype=bool)\n",
    "local_maxima[tuple(local_maxima_coords.T)] = True\n",
    "# use the local maxima to create seeds for the watershed algorithm\n",
    "seeds = label(local_maxima)\n",
    "# apply the watershed algorithm to segment the image and get labels\n",
    "labeled_ws_image = watershed(-distance_transform, seeds, mask=binary_mask_filled)\n",
    "\n",
    "# display resulting labeled_image overlaid onto raw_image\n",
    "seg_summary = label2rgb(labeled_ws_image, image=raw_image, bg_label=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
