{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899601d4",
   "metadata": {},
   "source": [
    "# Retraining Cellpose on Custom Data\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../../notebooks/05_segmentation/deep_learning/cellpose_retraining_notebook.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/05_segmentation/deep_learning/cellpose_retraining_notebook.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988ebd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"matplotlib\",\n",
    "#     \"tifffile\",\n",
    "#     \"cellpose\"\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca03c3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this section...\n",
    "\n",
    "If you do not have an Apple Silicon Mac or a GPU we suggest to run this notebook in Google Colab.\n",
    "\n",
    "...\n",
    "\n",
    "You need pair of raw data and respective labels.\n",
    "You can generate the labels in any way you want.\n",
    "you can for example follow the [Cellpose Documentation](https://cellpose.readthedocs.io/en/latest/gui.html#training-your-own-cellpose-model) and use the Cellpose GUI to manually update/create the labels.\n",
    "\n",
    "The images we will use for this section can be downloaded from the <a href=\"../../../_static/data/05_segmentation_cellpose_training.zip\" download> <i class=\"fas fa-download\"></i> Cellpose Training Dataset</a> (it contains both training and test images)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8a21f",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0b76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "from cellpose import core, io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5430eaff",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b8b8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:00,441 [INFO] WRITING LOG OUTPUT TO /Users/ranit/.cellpose/run.log\n",
      "2025-07-11 09:27:00,442 [INFO] \n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1\n",
      "2025-07-11 09:27:00,502 [INFO] ** TORCH MPS version installed and working. **\n",
      "GPU available: True\n"
     ]
    }
   ],
   "source": [
    "io.logger_setup()  # run this to get printing of progress\n",
    "\n",
    "print(\"GPU available:\", core.use_gpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0dc776",
   "metadata": {},
   "source": [
    "### Init the Model\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd65e527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:02,987 [INFO] ** TORCH MPS version installed and working. **\n",
      "2025-07-11 09:27:02,987 [INFO] >>>> using CPU\n",
      "2025-07-11 09:27:02,987 [INFO] >>>> using CPU\n",
      "2025-07-11 09:27:03,811 [INFO] >>>> loading model /Users/ranit/.cellpose/models/cpsam\n"
     ]
    }
   ],
   "source": [
    "from cellpose import core, io, models, plot\n",
    "from natsort import natsorted\n",
    "\n",
    "# Check if colab notebook instance has GPU access\n",
    "if core.use_gpu():\n",
    "    gpu = True\n",
    "else:\n",
    "    gpu = False\n",
    "    raise ImportError(\"No GPU access, change your runtime\")\n",
    "\n",
    "\n",
    "gpu = False\n",
    "# Initialize the Cellpose model\n",
    "model = models.CellposeModel(gpu=gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c9514",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "\n",
    "Training dataset vs Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5268c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:06,787 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-07-11 09:27:06,810 [INFO] 5 / 5 images in ../../../_static/data/05_segmentation_cellpose_training/train/ folder have labels\n",
      "2025-07-11 09:27:06,812 [INFO] not all flows are present, running flow generation for all images\n",
      "2025-07-11 09:27:06,829 [INFO] 3 / 3 images in ../../../_static/data/05_segmentation_cellpose_training/test/ folder have labels\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "ROOT_FOLDER_PATH = \"../../../_static/data/05_segmentation_cellpose_training/\"\n",
    "\n",
    "train_dir = os.path.join(ROOT_FOLDER_PATH, \"train/\")\n",
    "test_dir = os.path.join(ROOT_FOLDER_PATH, \"test/\")\n",
    "\n",
    "masks_ext = \"_seg.npy\"\n",
    "\n",
    "# get files\n",
    "train_data, train_labels, _, test_data, test_labels, _ = io.load_train_test_data(train_dir, test_dir, mask_filter=masks_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f87b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert images to float32\n",
    "train_data = [img.astype(np.float32) for img in train_data]\n",
    "# Convert labels (masks) to int32\n",
    "train_labels = [lbl.astype(np.int32) for lbl in train_labels]\n",
    "\n",
    "# Convert test images to float32 and labels to int32\n",
    "test_data = [img.astype(np.float32) for img in test_data]\n",
    "test_labels = [lbl.astype(np.int32) for lbl in test_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c583a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:27:09,482 [INFO] 0%|          | 0/3 [00:00<?, ?it/s]\n",
      "2025-07-11 09:27:49,597 [INFO] 33%|###3      | 1/3 [00:40<01:20, 40.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from cellpose import metrics\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(\"\")\n",
    "print(f\">>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400c63d",
   "metadata": {},
   "source": [
    "## Train new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8cae3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-10 21:42:42,210 [INFO] computing flows for labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:02<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-10 21:42:44,554 [INFO] >>> computing diameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:00<00:00, 403.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-10 21:42:44,569 [INFO] >>> normalizing {'lowhigh': None, 'percentile': None, 'normalize': True, 'norm3D': True, 'sharpen_radius': 0, 'smooth_radius': 0, 'tile_norm_blocksize': 0, 'tile_norm_smooth3D': 1, 'invert': False}\n",
      "2025-07-10 21:42:44,607 [INFO] >>> n_epochs=10, n_train=5, n_test=None\n",
      "2025-07-10 21:42:44,607 [INFO] >>> AdamW, learning_rate=0.00001, weight_decay=0.10000\n",
      "2025-07-10 21:42:44,628 [INFO] >>> saving model to /Users/ranit/Research/github/bobiac/content/05_segmentation/deep_learning/models/new_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected scalar_type == ScalarType::Float || inputTensor.scalar_type() == ScalarType::Int || scalar_type == ScalarType::Bool to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m batch_size = \u001b[32m1\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# (not passing test data into function to speed up training)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m new_model_path, train_losses, test_losses = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_seg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnimg_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# can change this\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/bobiac/lib/python3.13/site-packages/cellpose/train.py:468\u001b[39m, in \u001b[36mtrain_seg\u001b[39m\u001b[34m(net, train_data, train_labels, train_files, train_labels_files, train_probs, test_data, test_labels, test_files, test_labels_files, test_probs, channel_axis, load_files, batch_size, learning_rate, SGD, n_epochs, weight_decay, normalize, compute_flows, save_path, save_every, save_each, nimg_per_epoch, nimg_test_per_epoch, rescale, scale_range, bsize, min_train_masks, model_name, class_weights)\u001b[39m\n\u001b[32m    466\u001b[39m     loss += loss3\n\u001b[32m    467\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m optimizer.step()\n\u001b[32m    470\u001b[39m train_loss = loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/bobiac/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/bobiac/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/bobiac/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected scalar_type == ScalarType::Float || inputTensor.scalar_type() == ScalarType::Int || scalar_type == ScalarType::Bool to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)"
     ]
    }
   ],
   "source": [
    "from cellpose import train\n",
    "\n",
    "model_name = \"new_model\"\n",
    "\n",
    "# Training params\n",
    "n_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# (not passing test data into function to speed up training)\n",
    "\n",
    "new_model_path, train_losses, test_losses = train.train_seg(\n",
    "    model.net,\n",
    "    train_data=train_data,\n",
    "    train_labels=train_labels,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    nimg_per_epoch=max(2, len(train_data)),  # can change this\n",
    "    model_name=model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fcc0a6",
   "metadata": {},
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7148eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import metrics\n",
    "\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=new_model_path)\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, batch_size=32)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print(\"\")\n",
    "print(f\">>> average precision at iou threshold 0.5 = {ap[:, 0].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122fd87e",
   "metadata": {},
   "source": [
    "TO REMOVE: <a href=\"https://colab.research.google.com/github/MouseLand/cellpose/blob/main/notebooks/train_Cellpose-SAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91663123",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bobiac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
