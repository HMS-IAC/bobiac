{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a268f5ed",
   "metadata": {},
   "source": [
    "# Cellpose in Python\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../../notebooks/05_segmentation/deep_learning/cellpose_notebook.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/05_segmentation/deep_learning/cellpose_colab.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3bd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"matplotlib\",\n",
    "#     \"tifffile\",\n",
    "#     \"cellpose\"\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a63fe2e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[Website](https://www.cellpose.org) | [GitHub](https://github.com/mouseland/cellpose) | [Paper](https://www.biorxiv.org/content/10.1101/2025.04.28.651001v1)\n",
    "\n",
    "In this section...TO COMPLETE\n",
    "\n",
    "If you do not have an Apple Silicon Mac or a GPU we suggest to run this notebook in Google Colab. \n",
    "\n",
    "The images we will use for this section can be downloaded from the <a href=\"../../../_static/data/05_segmentation_cellpose.zip\"> <i class=\"fas fa-download\"></i> Cellpose Dataset</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437ad73",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d831fd3",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.6 \n",
      "platform:       \tdarwin \n",
      "python version: \t3.13.0 \n",
      "torch version:  \t2.7.1! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU execution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "from cellpose import core, io, models, plot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d9c3c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3369f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.logger_setup()  # to get printing of progress\n",
    "\n",
    "use_gpu = core.use_gpu()\n",
    "print(\"GPU available:\", use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72afec2",
   "metadata": {},
   "source": [
    "## Run Cellpose on A Sample Image\n",
    "\n",
    "In this section we will..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6139b9c",
   "metadata": {},
   "source": [
    "### Load the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc120648",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "image_path = \"../../../_static/images/cellpose/cell_cellpose.tif\"\n",
    "image = tifffile.imread(image_path)\n",
    "\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de800cb",
   "metadata": {},
   "source": [
    "### Initialize the Model\n",
    "\n",
    "To initialize Cellpose model we can use the [`models.CellposeModel()`](https://cellpose.readthedocs.io/en/latest/api.html#cellposemodel) class.\n",
    "\n",
    "Among the parameters we can set if we want to use `gpu` (if available) as well which **model** to use. The current default is Cellpose-SAM as `cpsam` (another example is `cyto3`, the previous U-Net-based model).\n",
    "\n",
    "If it is the first time you run this notebook, the model will be downloaded automatically. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac7d865",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "model = models.CellposeModel(gpu=use_gpu, model_type=\"cpsam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba06fe",
   "metadata": {},
   "source": [
    "### Run Cellpose\n",
    "\n",
    "After initializing the model, we can run it on the image using the [`model.eval()`](https://cellpose.readthedocs.io/en/latest/api.html#id0) method.\n",
    "\n",
    "Here are some of the parameters you can change:\n",
    "\n",
    "* ***flow_threshold*** is  the  maximum  allowed  error  of  the  flows  for  each  mask.   The  default  is 0.4.\n",
    "    *  **Increase** this threshold if cellpose is not returning as many masks as you’d expect (or turn off completely with 0.0)\n",
    "    *   **Decrease** this threshold if cellpose is returning too many ill-shaped masks.\n",
    "\n",
    "* ***cellprob_threshold*** determines proability that a detected object is a cell.   The  default  is 0.0.\n",
    "    *   **Decrease** this threshold if cellpose is not returning as many masks as you’d expect or if masks are too small\n",
    "    *   **Increase** this threshold if cellpose is returning too many masks esp from dull/dim areas.\n",
    "\n",
    "* ***tile_norm_blocksize*** determines the size of blocks used for normalizing the image. The default is 0, which means the entire image is normalized together.\n",
    "  You may want to change this to 100-200 pixels if you have very inhomogeneous brightness across your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a751e",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "channel = 0  # channel to use for cell detection, 0 cytoplasm, 1 nucleus\n",
    "\n",
    "# Cellpose parameters\n",
    "flow_threshold = 0.4\n",
    "cellprob_threshold = 0.0\n",
    "tile_norm_blocksize = 0\n",
    "\n",
    "masks, flows, styles = model.eval(\n",
    "    image[channel],\n",
    "    batch_size=32,\n",
    "    flow_threshold=flow_threshold,\n",
    "    cellprob_threshold=cellprob_threshold,\n",
    "    normalize={\"tile_norm_blocksize\": tile_norm_blocksize},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b3c09",
   "metadata": {},
   "source": [
    "### Display the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bfbd8f",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "plot.show_segmentation(fig, image[channel], masks, flows[0])\n",
    "plt.tight_layout()\n",
    "# Optional if you want to also save the figure\n",
    "# plt.savefig(f\"path/to/output/{Path(image_path).stem}_cp_output.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3e215",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "source": [
    "<div align=\"left\"> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/cellpose/cellpose_out.png\" alt=\"Ilastik Logo\" width=\"1000\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc88037",
   "metadata": {},
   "source": [
    "## Run Cellpose on a Folder of Images\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c62c4ea",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# folder_path = Path(\"data/05_segmentation_cellpose\")\n",
    "folder_path = Path(\"/Users/fdrgsp/Desktop/05_segmentation_cellpose\")\n",
    "\n",
    "# Read file names\n",
    "images = []\n",
    "for f in folder_path.glob(\"*.tif\"):\n",
    "    images.append(f)\n",
    "# same as running: files = [f for f in folder_path.glob(\"*.tif\")]\n",
    "\n",
    "# Cellpose parameters\n",
    "flow_threshold = 0.4\n",
    "cellprob_threshold = 0.0\n",
    "tile_norm_blocksize = 0\n",
    "\n",
    "# Run Cellpose on all images\n",
    "for image_path in tqdm(images):\n",
    "    image = tifffile.imread(image_path)\n",
    "    masks, flows, styles = model.eval(\n",
    "        image,\n",
    "        batch_size=32,\n",
    "        flow_threshold=flow_threshold,\n",
    "        cellprob_threshold=cellprob_threshold,\n",
    "        normalize={\"tile_norm_blocksize\": tile_norm_blocksize},\n",
    "    )\n",
    "\n",
    "    # Optional: display each image with its segmentation\n",
    "    # fig = plt.figure(figsize=(12, 5))\n",
    "    # plot.show_segmentation(fig, image, masks, flows[0])\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # Save the segmentation results\n",
    "    output_path = folder_path / f\"{image_path.stem}_labeled_mask.tif\"\n",
    "    tifffile.imwrite(output_path, masks.astype(\"uint16\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
