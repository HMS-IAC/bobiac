{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e296f4b",
   "metadata": {},
   "source": [
    "# Manders' Correlation Coefficients\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d447e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"matplotlib\",\n",
    "#     \"ndv[jupyter,vispy]\",\n",
    "#     \"scikit-image\",\n",
    "#     \"numpy\",\n",
    "#     \"scipy\",\n",
    "#     \"tifffile\",\n",
    "#     \"imagecodecs\",\n",
    "#     \"tqdm\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc72aa",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook, we will explore how to implement **Manders' Correlation Coefficients** in Python, a common method for quantifying colocalization based on pixel intensities.\n",
    "\n",
    "The images we will use for this section can be downloaded from the <a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a>.\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "   <strong>Note:</strong> This notebook aims to show how to practically implement these methods but does not aim to describe when to use this method. The images used have been selected to showcase the practical implementation of the methods.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "    <strong>Note:</strong> In this example, we will not perform any image processing steps before computing the Manders' Correlation Coefficients since the image provided has been corrected already. However, when conducting a real colocalization analysis, you should consider applying some image processing steps to clean the images before computing the Manders' Correlation Coefficients, such as background subtraction, flat-field correction, etc. \n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> In this notebook, we will only use a single image pair for demonstration purposes. Often, Manders' coefficients should not be interpreted as absolute values in isolation. Instead, it's always recommended to consider them in the context of comparisons between different conditions, controls, treatments, or experimental groups. The relative changes and ratios between conditions are often more meaningful than the absolute coefficient values themselves.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dd28d",
   "metadata": {},
   "source": [
    "## Manders' Correlation Coefficients\n",
    "\n",
    "Manders' correlation coefficients can be used to quantify the degree of colocalization between two channels (or images). These coefficients, M1 and M2, are calculated based on the pixel intensities of the two channels and for this reason, they are different from a simple area overlap.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/coloc/manders_slide.png\" alt=\"manders\" width=\"800\"></div>\n",
    "\n",
    "<br>\n",
    "\n",
    "**M1** measures the **fraction of channel 1 (**$R^{}$**) intensity that sits where channel 2 (**$G^{}$**) is present**:\n",
    "- **Numerator**: sum of channel 1 in every pixel (**$R_i^{}$**) where\n",
    "    - channel 2 is above the channel 2 threshold (**$G_i^{}$**), and\n",
    "    - channel 1 is above the channel 1 threshold (**$R_i^{}$**)(if you set one).\n",
    "- **Denominator**: sum of **$R_i^{}$** (channel 1) in every pixel where **$R_i^{}$** is above the **$R_i^{}$**-threshold.\n",
    "\n",
    "**M2** measures the **fraction of channel 2 (**$G^{}$**) intensity that sits where channel 1 (**$R^{}$**) is present**:\n",
    "- **Numerator**: sum of channel 2 in every pixel (**$G_i^{}$**) where\n",
    "\t1. channel 1 (**$R_i^{}$**) is above the channel 1 threshold (**$R_i^{}$**), and\n",
    "\t2. channel 2 (**$G_i^{}$**) is above the channel 2 threshold (**$G_i^{}$**) (if you set one).\n",
    "- **Denominator**: sum of channel 2 in every pixel (**$G_i^{}$**) where channel 2 (**$G_i^{}$**) is above the channel 2 threshold (**$G_i^{}$**).\n",
    "\n",
    "For this exercise, we will analyze an image of a HeLa cell stained with two fluorescent markers: **channel 1** labels **endosomes** and **channel 2** labels **lysosomes** (<a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i>Manders' & Pearson's Colocalization Dataset</a>.)\n",
    "\n",
    "From a biological perspective, lysosomes are typically found within or closely associated with endosomal compartments, while endosomes have a broader cellular distribution. Based on this biology, we expect:\n",
    "\n",
    "- **High M2 coefficient**: Most lysosomal signal should colocalize with endosomal regions\n",
    "- **Lower M1 coefficient**: Only a subset of endosomal signal should colocalize with lysosomes, since endosomes are more widely distributed throughout the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f616961",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f724dea6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.stats import pearsonr\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6900a",
   "metadata": {},
   "source": [
    "### Load and Visualize the Image\n",
    "\n",
    "Open and visualize (with ndv) the image named `cells_manders_14na.tif` from the <a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a>. This is a two-channel image where channel 1 has stained endosomes and channel 2 has stained lysosomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58157086",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Open the image\n",
    "img_path = \"../../_static/images/coloc/cells_manders_14na.tif\"\n",
    "img = tifffile.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca3d02",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the image\n",
    "ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea13af",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bc0d3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98764c14",
   "metadata": {},
   "source": [
    "To compute Manders' Correlation Coefficients, we need **two separate images** (channels). \n",
    "\n",
    "What is the image shape? How do we split the channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86327fbe",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get image shape\n",
    "print(\"Image shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d9bf352",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Split the image into channels\n",
    "ch1 = img[0]\n",
    "ch2 = img[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc303e",
   "metadata": {},
   "source": [
    "### Calculate Numerators and Denominators for Manders' Correlation Coefficients\n",
    "\n",
    "The first and key step is to calculate **$R_i^{}$** and **$G_i^{}$** and thus to select which areas of each channel we want to consider for the colocalization analysis. This means we first need to **threshold each images to select only the pixels we want to consider**.\n",
    "\n",
    "It is therefore evident that Manders' Correlation Coefficients are **sensitive to thresholding**, the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "For this example, we will first use a simple Otsu thresholding method and later in the notebook we will explore a more automated way of selecting the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d3aa1",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > threshold_otsu(ch1)\n",
    "image_2_mask = ch2 > threshold_otsu(ch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642f375",
   "metadata": {},
   "source": [
    "We can plot the raw data and the masks in a 2x2 subplot to visualize the results of the thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526f6cb",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce32fb",
   "metadata": {},
   "source": [
    "Now that we have the mask for each channel, we can first **calculate the overlap mask** where both channels are above their respective thresholds, and then calculate **$R_i^{coloc}$** and **$G_i^{coloc}$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81202e9",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask using a logical AND operation\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3076eb",
   "metadata": {},
   "source": [
    "With the overlap mask, we can now calculate the **$R_i^{coloc}$** (*ch1_coloc*) and **$G_i^{coloc}$** (*ch2_coloc*) and the **numerator** for the Manders' Correlation Coefficients: **sum($R_i^{coloc}$)** and **sum($G_i^{coloc}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103976dd",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9ff23",
   "metadata": {},
   "source": [
    "We can now **calculate the denominator** for the Manders coefficients.\n",
    "<br>\n",
    "The denominator is the sum of the pixel intensities in the overlap mask for each channel above their respective thresholds: **sum($R_i^{}$)** and **sum($G_i^{}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085491bf",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eaf3fb",
   "metadata": {},
   "source": [
    "### Calculate Manders' Correlation Coefficients\n",
    "\n",
    "Now with both numerators and denominators calculated, we can compute the Manders coefficients M1 and M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccf24f",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.2f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b68b8",
   "metadata": {},
   "source": [
    "With Otsu thresholding for both channels, we obtain:\n",
    "\n",
    "**M1=0.3496** and **M2=0.8975**\n",
    "\n",
    "- **M1** indicates that approximately **35%** (0.3496) of channel 1's intensity colocalizes with channel 2. This means that about one-third of channel 1's signal overlaps with areas where channel 2 is also present above threshold.\n",
    "\n",
    "- **M2** indicates that approximately **90%** (0.8975) of channel 2's intensity colocalizes with channel 1. This suggests that nearly all of channel 2's signal overlaps with areas where channel 1 is also present above threshold.\n",
    "\n",
    "This asymmetry (M1 ≠ M2) is common and tells us that **channel 2 is largely contained within areas where channel 1 is present**, but **channel 1 extends beyond the regions where channel 2 is found**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baf806",
   "metadata": {},
   "source": [
    "**Bonus**: In the <a href=\"../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Manders' & Pearson's Colocalization Dataset</a> there is an image named `cells_manders_0.3na.tif`, the exact same image we just used nut acquired with a smaller numerical aperture (NA) of the objective lens.\n",
    "\n",
    "What do you think will happen to the Manders' coefficients if we use this image instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fedfc5",
   "metadata": {},
   "source": [
    "### Costes Auto-Threshold Method\n",
    "\n",
    "As mentioned above, the Mender's Correlation Coefficients are sensitive to thresholding, so the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "The function `costes_auto_threshold` below implements the [Costes auto-threshold method](https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/), which **automatically determines optimal threshold values for both channels**. \n",
    "\n",
    "The method works by finding threshold values where pixels *below* these thresholds show no statistical correlation (Pearson correlation coefficient ≈ 0). This approach helps objectively separate true signal from background noise.    The algorithm performs orthogonal regression (PCA) between the two channels to establish their relationship, then iteratively tests threshold pairs derived from this regression to identify the optimal separation point between signal and background.\n",
    "\n",
    "Of course, the Costes auto-threshold method has limitations and may not work in certain scenarios, including:\n",
    "- **Insufficient data**: When there are too few non-zero pixels (< 10) in either channel\n",
    "- **No linear relationship**: When channels show non-linear, multiple population, or no correlation patterns.\n",
    "- **Low variance**: When one or both channels have uniform or near-uniform intensities\n",
    "- **High background noise**: When noise dominates the signal relationship\n",
    "- **Limited dynamic range**: Narrow intensity ranges or saturated pixels\n",
    "\n",
    "In such cases, alternative thresholding methods (Otsu, manual, percentile-based) may be more appropriate.\n",
    "\n",
    "We can now try to compute and print the Manders' Correlation Coefficients using the Costes auto-threshold method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04775d7",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def costes_auto_threshold(\n",
    "    ch1: np.ndarray,\n",
    "    ch2: np.ndarray,\n",
    "    num_thresholds: int = 100,\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Implementation of Costes auto-threshold method for colocalization analysis.\n",
    "\n",
    "    Based on:\n",
    "    Costes et al. \"Automatic and quantitative measurement of protein-protein\n",
    "    colocalization in live cells\" Biophysical Journal 2004\n",
    "    https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/\n",
    "\n",
    "    The method finds thresholds where the Pearson correlation coefficient\n",
    "    of pixels below the thresholds equals zero, indicating that pixels\n",
    "    below these thresholds show no statistical correlation.\n",
    "\n",
    "    This implementation ensures symmetric results regardless of channel order.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    ch1: np.ndarray\n",
    "        First channel image data (2D array).\n",
    "    ch2: np.ndarray\n",
    "        Second channel image data (2D array).\n",
    "    num_thresholds: int\n",
    "        Number of threshold values to test along the regression line. By default, 100.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    tuple: (threshold_ch1, threshold_ch2, slope, intercept)\n",
    "        Optimal thresholds for channel 1 and channel 2, slope and intercept of the\n",
    "        regression line that relates ch2 to ch1 (ch2 = slope * ch1 + intercept).\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten images for easier processing\n",
    "    ch1_flat = ch1.ravel()\n",
    "    ch2_flat = ch2.ravel()\n",
    "\n",
    "    # If the min value is zero, consider only non-zero pixels\n",
    "    if np.min(ch1_flat) == 0 or np.min(ch2_flat) == 0:\n",
    "        mask = (ch1_flat > 0) & (ch2_flat > 0)\n",
    "        ch1_masked = ch1_flat[mask]\n",
    "        ch2_masked = ch2_flat[mask]\n",
    "    else:\n",
    "        ch1_masked = ch1_flat\n",
    "        ch2_masked = ch2_flat\n",
    "\n",
    "    if len(ch1_masked) == 0 or len(ch2_masked) == 0:\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "    # Center the data\n",
    "    ch1_mean = np.mean(ch1_masked)\n",
    "    ch2_mean = np.mean(ch2_masked)\n",
    "    ch1_centered = ch1_masked - ch1_mean\n",
    "    ch2_centered = ch2_masked - ch2_mean\n",
    "\n",
    "    # Perform PCA to find the orthogonal regression line\n",
    "    data = np.vstack([ch1_centered, ch2_centered]).T\n",
    "    cov_matrix = np.cov(data.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # The first principal component is the eigenvector with largest eigenvalue\n",
    "    principal_component = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "\n",
    "    # Normalize the principal component\n",
    "    pc_norm = principal_component / np.linalg.norm(principal_component)\n",
    "\n",
    "    # Project all points onto the principal component line\n",
    "    projections = ch1_centered * pc_norm[0] + ch2_centered * pc_norm[1]\n",
    "\n",
    "    # Generate threshold parameters along the line\n",
    "    proj_min, proj_max = np.min(projections), np.max(projections)\n",
    "    t_values = np.linspace(proj_max, proj_min, num_thresholds)\n",
    "\n",
    "    best_thr_ch1 = best_thr_ch2 = 0\n",
    "    best_correlation = 1.0\n",
    "\n",
    "    for t in t_values:\n",
    "        # Convert parameter t back to (ch1, ch2) coordinates\n",
    "        thr_ch1 = ch1_mean + t * pc_norm[0]\n",
    "        thr_ch2 = ch2_mean + t * pc_norm[1]\n",
    "\n",
    "        # Skip if threshold is outside data range\n",
    "        if (\n",
    "            thr_ch1 < np.min(ch1_masked)\n",
    "            or thr_ch1 > np.max(ch1_masked)\n",
    "            or thr_ch2 < np.min(ch2_masked)\n",
    "            or thr_ch2 > np.max(ch2_masked)\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Create mask for pixels below thresholds\n",
    "        below_mask = (ch1_masked < thr_ch1) & (ch2_masked < thr_ch2)\n",
    "\n",
    "        if np.sum(below_mask) < 10:  # Need minimum number of pixels\n",
    "            continue\n",
    "\n",
    "        # Calculate correlation for pixels below threshold\n",
    "        ch1_below = ch1_masked[below_mask]\n",
    "        ch2_below = ch2_masked[below_mask]\n",
    "\n",
    "        if len(ch1_below) > 1 and np.std(ch1_below) > 0 and np.std(ch2_below) > 0:\n",
    "            correlation, _ = pearsonr(ch1_below, ch2_below)\n",
    "\n",
    "            # Find threshold where correlation is closest to zero\n",
    "            if abs(correlation) < abs(best_correlation):\n",
    "                best_correlation = correlation\n",
    "                best_thr_ch1 = thr_ch1\n",
    "                best_thr_ch2 = thr_ch2\n",
    "\n",
    "    # Calculate slope and intercept for reporting\n",
    "    slope = pc_norm[1] / pc_norm[0]\n",
    "    intercept = ch2_mean - slope * ch1_mean\n",
    "\n",
    "    return best_thr_ch1, best_thr_ch2, slope, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792a0a6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "source": [
    "### Calculate Manders' Coefficients with Costes Auto-Thresholds\n",
    "\n",
    "Calculate the Costes auto-thresholds for the two channels and print the thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c817765",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Costes auto-thresholds for the two channels\n",
    "costes_thr_ch1, costes_thr_ch2, slope, intercept = costes_auto_threshold(ch1, ch2)\n",
    "print(\n",
    "    \"Costes thresholds:\\n\"\n",
    "    f\"Channel 1 = {costes_thr_ch1}\\n\"\n",
    "    f\"Channel 2 = {costes_thr_ch2}\\n\"\n",
    "    f\"Regression Eq: y = {slope:.4f} * x + {intercept:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122d27c6",
   "metadata": {},
   "source": [
    "**Bonus:** Plot also a scatter plot of the two channels with the linear regression line.\n",
    "\n",
    "Note that the `costes_auto_threshold` function returns (in order) *Costes thresholds for channel 1*, *Costes thresholds for channel 2*, *slope* and *intercept* of the linear regression. We can use the slope and intercept to plot the linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc34d97",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# plot scatter plot of the two channels with thresholds\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(ch1.ravel(), ch2.ravel(), s=1, alpha=0.5)\n",
    "plt.axvline(costes_thr_ch1, color=\"green\", linestyle=\"--\", label=\"Threshold ch1\")\n",
    "plt.axhline(costes_thr_ch2, color=\"magenta\", linestyle=\"--\", label=\"Threshold ch2\")\n",
    "x_vals = np.unique(ch1.ravel())  # Get unique intensity values from ch1\n",
    "y_vals = slope * x_vals + intercept\n",
    "plt.plot(\n",
    "    x_vals, y_vals, color=\"k\", linestyle=\"--\", label=\"Regression line\", linewidth=2\n",
    ")\n",
    "plt.xlabel(\"Channel 1 Intensity\")\n",
    "plt.ylabel(\"Channel 2 Intensity\")\n",
    "plt.title(\"Costes Auto-Threshold Scatter Plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8604302",
   "metadata": {},
   "source": [
    "Now that we have the Costes thresholds, we can calculate the Manders' Correlation Coefficients using the Costes thresholds as we did for the Otsu thresholds.\n",
    "\n",
    "How do thresholds and mask images compare to the Otsu thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b35b8",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > costes_thr_ch1\n",
    "image_2_mask = ch2 > costes_thr_ch2\n",
    "\n",
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87520e4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccc9b2",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)\n",
    "\n",
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)\n",
    "\n",
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.2f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf50d3",
   "metadata": {},
   "source": [
    "### Image Rotation Test\n",
    "\n",
    "The **image rotation**, in this context, is a statistical method to validate colocalization significance. This method applies **rotations (90°, 180°, 270°) and flips (horizontal and vertical)** to one channel relative to the other, then recalculates the Manders' coefficients.\n",
    "\n",
    "**Note for Non-Square Images:** When working with non-square images, rotations by 90° and 270° would change the image dimensions (e.g., a 500×512 image becomes 512×500), making direct comparison impossible. To handle this, the function automatically pads non-square images to square dimensions with zeros before applying rotations, ensuring that all transformations maintain the same image size and allow valid statistical comparisons.\n",
    "\n",
    "Below you can find an implementation of this method in Python. This function returns the Manders' coefficients, the rotated/flipped Manders' coefficients, and the p-values for both coefficients.\n",
    "\n",
    "A low `p-value` (e.g. 0.0001) means that none of the rotations/flips produced M1/M2 values as high as the observed values without translation, indicating that the observed colocalization is statistically significant: the probability of getting the observed colocalization by random chance is < 0.0001 (less than 0.01%).\n",
    "\n",
    "Let's run it on the two channels we have been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b8f3f",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def image_rotation_test(\n",
    "    channel_1: np.ndarray,\n",
    "    channel_2: np.ndarray,\n",
    "    threshold_ch1: float = 0.0,\n",
    "    threshold_ch2: float = 0.0,\n",
    ") -> tuple[float, float, list[float], list[float], float, float]:\n",
    "    \"\"\"\n",
    "    Perform image rotation randomization test for Manders' coefficients validation.\n",
    "\n",
    "    This method applies systematic rotations (90°, 180°, 270°) and flips to one channel\n",
    "    relative to the other, breaking spatial relationships while preserving local patterns.\n",
    "\n",
    "    For non-square images, the function automatically pads them to square dimensions\n",
    "    with zeros before applying rotations to ensure valid comparisons.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    channel_1 : np.ndarray\n",
    "        First fluorescent channel (kept fixed)\n",
    "    channel_2 : np.ndarray\n",
    "        Second fluorescent channel (will be rotated and flipped)\n",
    "    threshold_ch1 : float, optional\n",
    "        Intensity threshold for channel 1\n",
    "    threshold_ch2 : float, optional\n",
    "        Intensity threshold for channel 2\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple containing:\n",
    "        - float: Observed M1 coefficient\n",
    "        - float: Observed M2 coefficient\n",
    "        - List[float]: M1 coefficients from rotation/flip iterations\n",
    "        - List[float]: M2 coefficients from rotation/flip iterations\n",
    "        - float: P-value for M1 (fraction of rotation M1 >= observed M1)\n",
    "        - float: P-value for M2 (fraction of rotation M2 >= observed M2)\n",
    "    \"\"\"\n",
    "\n",
    "    def _pad_to_square(image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Pad image to square dimensions with zeros.\"\"\"\n",
    "        h, w = image.shape\n",
    "        max_dim = max(h, w)\n",
    "        # Calculate padding needed\n",
    "        pad_h = (max_dim - h) // 2\n",
    "        pad_w = (max_dim - w) // 2\n",
    "        # Pad the image symmetrically\n",
    "        padded = np.pad(\n",
    "            image,\n",
    "            ((pad_h, max_dim - h - pad_h), (pad_w, max_dim - w - pad_w)),\n",
    "            mode=\"constant\",\n",
    "            constant_values=0,\n",
    "        )\n",
    "\n",
    "        return padded\n",
    "\n",
    "    def _calculate_manders(\n",
    "        ch1: np.ndarray, ch2: np.ndarray, thresh_ch1: float, thresh_ch2: float\n",
    "    ) -> tuple[float, float]:\n",
    "        \"\"\"Helper function to calculate Manders' correlation coefficients.\"\"\"\n",
    "        # Apply thresholds and get overlap mask\n",
    "        mask_a = ch1 > thresh_ch1\n",
    "        mask_b = ch2 > thresh_ch2\n",
    "        overlap_mask = mask_a & mask_b\n",
    "\n",
    "        # Calculate M1: fraction of A overlapping with B\n",
    "        m1_numerator = np.sum(ch1[overlap_mask])\n",
    "        m1_denominator = np.sum(ch1[mask_a])\n",
    "        m1 = m1_numerator / m1_denominator if m1_denominator > 0 else 0.0\n",
    "\n",
    "        # Calculate M2: fraction of B overlapping with A\n",
    "        m2_numerator = np.sum(ch2[overlap_mask])\n",
    "        m2_denominator = np.sum(ch2[mask_b])\n",
    "        m2 = m2_numerator / m2_denominator if m2_denominator > 0 else 0.0\n",
    "\n",
    "        return m1, m2\n",
    "\n",
    "    def _rotate_and_flip_image(\n",
    "        image: np.ndarray, rotation: int, flip_type: str\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Rotate image by specified angle and optionally flip.\"\"\"\n",
    "        # Apply rotation (k=1 means 90°, k=2 means 180°, k=3 means 270°)\n",
    "        rotated = np.rot90(image, k=rotation)\n",
    "\n",
    "        # Apply flip if requested\n",
    "        if flip_type == \"horizontal\":\n",
    "            rotated = np.fliplr(rotated)\n",
    "        elif flip_type == \"vertical\":\n",
    "            rotated = np.flipud(rotated)\n",
    "\n",
    "        return rotated\n",
    "\n",
    "    # Check if images are square, if not pad them\n",
    "    if (\n",
    "        channel_1.shape[0] != channel_1.shape[1]\n",
    "        or channel_2.shape[0] != channel_2.shape[1]\n",
    "    ):\n",
    "        # Pad both channels to square dimensions\n",
    "        channel_1_padded = _pad_to_square(channel_1)\n",
    "        channel_2_padded = _pad_to_square(channel_2)\n",
    "    else:\n",
    "        channel_1_padded = channel_1\n",
    "        channel_2_padded = channel_2\n",
    "\n",
    "    # Calculate observed Manders' coefficients\n",
    "    observed_m1, observed_m2 = _calculate_manders(\n",
    "        channel_1_padded, channel_2_padded, threshold_ch1, threshold_ch2\n",
    "    )\n",
    "\n",
    "    # Initialize lists to store rotation/flip coefficients\n",
    "    rotation_m1_values = []\n",
    "    rotation_m2_values = []\n",
    "\n",
    "    # Apply all combinations of rotations and flips\n",
    "    transformations = [\n",
    "        (1, None),  # 90° rotation\n",
    "        (1, \"horizontal\"),  # 90° rotation + horizontal flip\n",
    "        (1, \"vertical\"),  # 90° rotation + vertical flip\n",
    "        (2, None),  # 180° rotation\n",
    "        (2, \"horizontal\"),  # 180° rotation + horizontal flip\n",
    "        (2, \"vertical\"),  # 180° rotation + vertical flip\n",
    "        (3, None),  # 270° rotation\n",
    "        (3, \"horizontal\"),  # 270° rotation + horizontal flip\n",
    "        (3, \"vertical\"),  # 270° rotation + vertical flip\n",
    "    ]\n",
    "\n",
    "    for rotation, flip_type in transformations:\n",
    "        # Apply rotation and flip to channel 2 (using padded version)\n",
    "        transformed_ch2 = _rotate_and_flip_image(channel_2_padded, rotation, flip_type)\n",
    "\n",
    "        # Calculate Manders' coefficients with transformed channel 2\n",
    "        rotation_m1, rotation_m2 = _calculate_manders(\n",
    "            channel_1_padded, transformed_ch2, threshold_ch1, threshold_ch2\n",
    "        )\n",
    "        rotation_m1_values.append(rotation_m1)\n",
    "        rotation_m2_values.append(rotation_m2)\n",
    "\n",
    "    # Calculate p-values\n",
    "    n_transformations = len(rotation_m1_values)\n",
    "    p_value_m1 = np.sum(np.array(rotation_m1_values) >= observed_m1) / n_transformations\n",
    "    p_value_m2 = np.sum(np.array(rotation_m2_values) >= observed_m2) / n_transformations\n",
    "\n",
    "    return (\n",
    "        observed_m1,\n",
    "        observed_m2,\n",
    "        rotation_m1_values,\n",
    "        rotation_m2_values,\n",
    "        p_value_m1,\n",
    "        p_value_m2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7b1beb",
   "metadata": {},
   "source": [
    "Calculate either the Otsu or Costes thresholds for the two channels and then run the image translation randomization test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60b2b9a",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "thr_1, thr_2 = threshold_otsu(ch1), threshold_otsu(ch2)\n",
    "# thr_1, thr_2, _, _ = costes_auto_threshold(ch1, ch2)\n",
    "\n",
    "# Run the rotation test\n",
    "rotation_values = image_rotation_test(ch1, ch2, thr_1, thr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c9f19",
   "metadata": {},
   "source": [
    "We can now print the results of the analysis: M1, M2, and their respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc06ea",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Extract results\n",
    "(\n",
    "    M1,\n",
    "    M2,\n",
    "    rot_m1_values,\n",
    "    rot_m2_values,\n",
    "    p_value_m1_rot,\n",
    "    p_value_m2_rot,\n",
    ") = rotation_values\n",
    "# Print results\n",
    "print(f\"M1: {M1:.2f}, p-value: {p_value_m1_rot:.4f}\")\n",
    "print(f\"M2: {M2:.2f}, p-value: {p_value_m2_rot:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473fc032",
   "metadata": {},
   "source": [
    "**Bonus:** We can also visualize the distribution of the random M1 and M2 values using a bar plot.\n",
    "\n",
    "To do this is useful to know that the transformations applied in `image_rotation_test` are 9:\n",
    "- 90°\n",
    "- 90° + Flip horizontally\n",
    "- 90° + Flip vertically\n",
    "- 180°\n",
    "- 180° + Flip horizontally\n",
    "- 180° + Flip vertically\n",
    "- 270°\n",
    "- 270° + Flip horizontally\n",
    "- 270° + Flip vertically\n",
    "\n",
    "We can use this information to plot the bar plot with the M1 and M2 values for each transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69fb93",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize rotation randomization results - Individual Transformation Results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "transformations_names = [\n",
    "    \"90°\",\n",
    "    \"90°_flip_h\",\n",
    "    \"90°_flip_v\",\n",
    "    \"180°\",\n",
    "    \"180°_flip_h\",\n",
    "    \"180°_flip_v\",\n",
    "    \"270°\",\n",
    "    \"270°_flip_h\",\n",
    "    \"270°_flip_v\",\n",
    "]\n",
    "\n",
    "# Bar chart showing individual transformation results\n",
    "transformation_indices = range(len(transformations_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(\n",
    "    [i - width / 2 for i in transformation_indices],\n",
    "    rot_m1_values,\n",
    "    width,\n",
    "    label=\"M1\",\n",
    "    color=\"magenta\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.bar(\n",
    "    [i + width / 2 for i in transformation_indices],\n",
    "    rot_m2_values,\n",
    "    width,\n",
    "    label=\"M2\",\n",
    "    color=\"green\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.axhline(\n",
    "    M1, color=\"magenta\", linestyle=\"--\", linewidth=2, alpha=0.8, label=\"Observed M1\"\n",
    ")\n",
    "ax.axhline(\n",
    "    M2, color=\"green\", linestyle=\"--\", linewidth=2, alpha=0.8, label=\"Observed M2\"\n",
    ")\n",
    "ax.set_xlabel(\"Transformation\")\n",
    "ax.set_ylabel(\"Manders Coefficient\")\n",
    "ax.set_title(\n",
    "    f\"Individual Transformation Results (M1 p-value: {p_value_m1_rot:.3f}, \"\n",
    "    f\"M2 p-value: {p_value_m2_rot:.3f})\"\n",
    ")\n",
    "ax.set_xticks(transformation_indices)\n",
    "ax.set_xticklabels(\n",
    "    [name.replace(\" + \", \"\\n+ \") for name in transformations_names],\n",
    "    ha=\"center\",\n",
    "    fontsize=8,\n",
    ")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be7657",
   "metadata": {},
   "source": [
    "### Image Translation Randomization Test\n",
    "\n",
    "The **image translation randomization** test is a statistical method used to **validate the significance of colocalization results**, particularly for Manders' coefficients. This method involves **randomly translating one channel relative to another and recalculating the Manders' coefficients** to create a distribution of values under the null hypothesis of no colocalization.\n",
    "\n",
    "**Note for Image Translations:** Unlike rotations, translations use wraparound shifting (via `np.roll()`) which preserves the original image dimensions regardless of image shape. When pixels are shifted beyond the image boundaries, they wrap around to the opposite side. This ensures that all pixel intensities are preserved and no padding is required, making this method suitable for images of any dimensions.\n",
    "\n",
    "Below you can find an implementation of this method in Python. This function returns the Manders' coefficients, the random Manders' coefficients, and the p-values for both coefficients.\n",
    "\n",
    "A low `p-value` (e.g. 0.0001) means that none of the `n` random translations (by default 1000) produced M1/M2 values as high as the observed values without translation, indicating that the observed colocalization is statistically significant: the probability of getting the observed colocalization by random chance is < 0.0001 (less than 0.01%).\n",
    "\n",
    "Let's run it on the two channels we have been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0797d",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def image_translation_randomization(\n",
    "    channel_1: np.ndarray,\n",
    "    channel_2: np.ndarray,\n",
    "    threshold_ch1: float = 0.0,\n",
    "    threshold_ch2: float = 0.0,\n",
    "    n_iterations: int = 1000,\n",
    "    max_shift_fraction: float = 0.5,\n",
    "    seed: int = 3,\n",
    ") -> tuple[float, float, list[float], list[float], float, float]:\n",
    "    \"\"\"\n",
    "    Perform image translation randomization test for Manders' coefficients validation.\n",
    "\n",
    "    This method applies random translations (shifts) to one channel relative to the other,\n",
    "    breaking spatial relationships while preserving intensity distributions and local patterns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    channel_1 : np.ndarray\n",
    "        First fluorescent channel (kept fixed)\n",
    "    channel_2 : np.ndarray\n",
    "        Second fluorescent channel (will be translated)\n",
    "    threshold_ch1 : float, optional\n",
    "        Intensity threshold for channel A (if None, uses Otsu's method)\n",
    "    threshold_ch2 : float, optional\n",
    "        Intensity threshold for channel B (if None, uses Otsu's method)\n",
    "    n_iterations : int\n",
    "        Number of randomization iterations (default: 1000)\n",
    "    max_shift_fraction : float\n",
    "        Maximum shift as fraction of image dimensions (default: 0.5)\n",
    "    seed : int\n",
    "        Random numpy seed for reproducibility (default: 3)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple containing:\n",
    "        - List[float]: M1 coefficients from randomized iterations (A overlap with B)\n",
    "        - List[float]: M2 coefficients from randomized iterations (B overlap with A)\n",
    "        - float: Observed M1 coefficient\n",
    "        - float: Observed M2 coefficient\n",
    "        - float: P-value for M1 (fraction of random M1 >= observed M1)\n",
    "        - float: P-value for M2 (fraction of random M2 >= observed M2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set numpy random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    def _calculate_manders(\n",
    "        ch1: np.ndarray, ch2: np.ndarray, thresh_ch1: float, thresh_ch2: float\n",
    "    ) -> tuple[float, float]:\n",
    "        \"\"\"Helper function to calculate Manders' correlations coefficients.\"\"\"\n",
    "        # Apply thresholds and get overlap mask\n",
    "        mask_a = ch1 > thresh_ch1\n",
    "        mask_b = ch2 > thresh_ch2\n",
    "        overlap_mask = mask_a & mask_b\n",
    "\n",
    "        # Calculate M1: fraction of A overlapping with B\n",
    "        m1_numerator = np.sum(ch1[overlap_mask])\n",
    "        m1_denominator = np.sum(ch1[mask_a])\n",
    "        m1 = m1_numerator / m1_denominator if m1_denominator > 0 else 0.0\n",
    "\n",
    "        # Calculate M2: fraction of B overlapping with A\n",
    "        m2_numerator = np.sum(ch2[overlap_mask])\n",
    "        m2_denominator = np.sum(ch2[mask_b])\n",
    "        m2 = m2_numerator / m2_denominator if m2_denominator > 0 else 0.0\n",
    "\n",
    "        return m1, m2\n",
    "\n",
    "    def _translate_image(image: np.ndarray, shift_y: int, shift_x: int) -> np.ndarray:\n",
    "        \"\"\"Translate image by given shifts with wrap-around.\"\"\"\n",
    "        return np.roll(np.roll(image, shift_y, axis=0), shift_x, axis=1)\n",
    "\n",
    "    # Calculate observed Manders' coefficients\n",
    "    observed_m1, observed_m2 = _calculate_manders(\n",
    "        channel_1, channel_2, threshold_ch1, threshold_ch2\n",
    "    )\n",
    "\n",
    "    # Calculate maximum shifts\n",
    "    max_shift_y = int(channel_2.shape[0] * max_shift_fraction)\n",
    "    max_shift_x = int(channel_2.shape[1] * max_shift_fraction)\n",
    "\n",
    "    # Initialize lists to store randomized coefficients\n",
    "    random_m1_values = []\n",
    "    random_m2_values = []\n",
    "\n",
    "    # for _ in tqdm(range(n_iterations), desc=\"Image translation randomization\"):\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random shifts (excluding zero shift)\n",
    "        shift_y = np.random.randint(-max_shift_y, max_shift_y + 1)\n",
    "        shift_x = np.random.randint(-max_shift_x, max_shift_x + 1)\n",
    "\n",
    "        # Ensure at least one shift is non-zero\n",
    "        if shift_y == 0 and shift_x == 0:\n",
    "            shift_y = np.random.choice([-1, 1])\n",
    "\n",
    "        # Apply translation to channel B\n",
    "        translated_ch2 = _translate_image(channel_2, shift_y, shift_x)\n",
    "\n",
    "        # Calculate Manders' coefficients with translated channel B\n",
    "        random_m1, random_m2 = _calculate_manders(\n",
    "            channel_1, translated_ch2, threshold_ch1, threshold_ch2\n",
    "        )\n",
    "        random_m1_values.append(random_m1)\n",
    "        random_m2_values.append(random_m2)\n",
    "\n",
    "    # Calculate p-values\n",
    "    p_value_m1 = np.sum(np.array(random_m1_values) >= observed_m1) / n_iterations\n",
    "    p_value_m2 = np.sum(np.array(random_m2_values) >= observed_m2) / n_iterations\n",
    "\n",
    "    return (\n",
    "        observed_m1,\n",
    "        observed_m2,\n",
    "        random_m1_values,\n",
    "        random_m2_values,\n",
    "        p_value_m1,\n",
    "        p_value_m2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa84e570",
   "metadata": {},
   "source": [
    "Calculate either the Otsu or Costes thresholds for the two channels and then run the image translation randomization test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169660a4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "thr_1, thr_2 = threshold_otsu(ch1), threshold_otsu(ch2)\n",
    "# thr_1, thr_2, _, _ = costes_auto_threshold(ch1, ch2)\n",
    "\n",
    "values = image_translation_randomization(ch1, ch2, thr_1, thr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc1dd3",
   "metadata": {},
   "source": [
    "We can now print the results of the analysis: M1, M2, and their respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c24fa1",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "M1, M2, random_m1_values, random_m2_values, p_value_m1, p_value_m2 = values\n",
    "print(f\"M1: {M1:.4f}, p-value: {p_value_m1:.4f}\")\n",
    "print(f\"M2: {M2:.4f}, p-value: {p_value_m2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c4eb5",
   "metadata": {},
   "source": [
    "**Bonus:** We can also visualize the distribution of the random M1 and M2 values using histograms. This will help us understand the significance of our observed values in the context of the random distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb4864",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# plot the distribution of random M1 and M2 values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(random_m1_values, bins=50, color=\"magenta\", alpha=0.7, label=\"Random M1\")\n",
    "plt.axvline(M1, color=\"k\", linestyle=\"--\", label=\"Observed M1\")\n",
    "plt.xlabel(\"M1 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M1 Values\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_m2_values, bins=50, color=\"green\", alpha=0.7, label=\"Random M2\")\n",
    "plt.axvline(M2, color=\"k\", linestyle=\"--\", label=\"Observed M2\")\n",
    "plt.xlabel(\"M2 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M2 Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc21c1a",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The Python implementation for calculating Manders' Correlation Coefficients is straightforward and concise, as demonstrated in the code below.\n",
    "\n",
    "```python\n",
    "# Create binary mask for channel 1 & 2 using a thresholding method of choice\n",
    "threshold_ch1, threshold_ch2 = threshold_method(ch1, ch2)\n",
    "image_1_mask = ch1 > threshold_ch1\n",
    "image_2_mask = ch2 > threshold_ch2\n",
    "\n",
    "# Find pixels that are above threshold in both channels\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Extract channel 1 & 2 intensities only from overlapping regions\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Extract all channel 1 & 2 intensities above threshold\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "\n",
    "# Calculate total intensity of channel 1 & 2 above threshold\n",
    "sum_ch1_tr = np.sum(ch1_tr)\n",
    "sum_ch2_tr = np.sum(ch2_tr)\n",
    "\n",
    "# M1: fraction of channel 1 intensity that colocalizes with channel 2\n",
    "M1 = np.sum(ch1_coloc) / sum_ch1_tr\n",
    "# M2: fraction of channel 2 intensity that colocalizes with channel 1\n",
    "M2 = np.sum(ch2_coloc) / sum_ch2_tr\n",
    "```\n",
    "\n",
    "**Key Considerations for Manders' Correlation Analysis:**\n",
    "\n",
    "1. **Threshold Sensitivity**: Manders' coefficients are **highly sensitive to thresholding methods**. The choice of thresholding strategy will significantly impact your results, making careful threshold selection essential for accurate colocalization analysis. Consider using:\n",
    "   - **Automated thresholding methods** (like Costes auto-threshold): these are fully automated and don't require you to select or tune any parameters\n",
    "   - **Threshold calculation algorithms** (like Otsu, Li, Triangle, Yen, etc.): these automatically calculate a threshold value, but you need to choose which algorithm to use based on your image characteristics and how the resulting threshold looks\n",
    "   - **Consistent thresholding**: use the same thresholding approach across experimental conditions\n",
    "\n",
    "2. **Background Considerations**: sometimes it is necessary to apply appropriate image preprocessing steps before calculating Manders' coefficients such as Background subtraction to remove non-specific signal or Flat-field correction to account for illumination variations.\n",
    "\n",
    "3. **Statistical Validation**: always validate your results using statistical tests such as the image rotation test or the image translation randomization test demonstrated above. This helps assess whether observed colocalization is statistically significant or could have occurred by chance.\n",
    "\n",
    "4. **Comparative Analysis**: Manders' coefficients should not be interpreted as absolute values in isolation. Instead, consider them in the context of:\n",
    "   - Comparisons between different experimental conditions\n",
    "   - Control vs. treatment groups\n",
    "   - Different time points or developmental stages\n",
    "   - Relative changes between conditions are often more meaningful than absolute values\n",
    "\n",
    "5. **Asymmetry Interpretation**: remember that M1 ≠ M2 is common and biologically meaningful.\n",
    "   - **M1**: Fraction of channel 1 intensity that overlaps with channel 2\n",
    "   - **M2**: Fraction of channel 2 intensity that overlaps with channel 1\n",
    "   - This asymmetry can reveal important biological relationships between the labeled structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bd05fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costes_auto_threshold_jacop_compatible(\n",
    "    ch1: np.ndarray, ch2: np.ndarray\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Clean implementation of Costes auto-threshold compatible with Fiji BIOP JACOP.\n",
    "\n",
    "    Uses orthogonal regression (PCA) and correlation-based threshold search\n",
    "    to find optimal thresholds for colocalization analysis.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ch1 : np.ndarray\n",
    "        First channel image (2D array)\n",
    "    ch2 : np.ndarray\n",
    "        Second channel image (2D array)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple: (threshold_ch1, threshold_ch2, manders_m1, manders_m2)\n",
    "        - threshold_ch1: Optimal threshold for channel 1\n",
    "        - threshold_ch2: Optimal threshold for channel 2\n",
    "        - manders_m1: Manders' coefficient M1\n",
    "        - manders_m2: Manders' coefficient M2\n",
    "    \"\"\"\n",
    "    # Flatten and remove zero pixels\n",
    "    ch1_flat = ch1.flatten()\n",
    "    ch2_flat = ch2.flatten()\n",
    "    nonzero_mask = (ch1_flat > 0) & (ch2_flat > 0)\n",
    "    ch1_nz = ch1_flat[nonzero_mask].astype(np.int32)\n",
    "    ch2_nz = ch2_flat[nonzero_mask].astype(np.int32)\n",
    "\n",
    "    # Orthogonal regression (PCA)\n",
    "    ch1_mean = np.mean(ch1_nz)\n",
    "    ch2_mean = np.mean(ch2_nz)\n",
    "    ch1_centered = ch1_nz - ch1_mean\n",
    "    ch2_centered = ch2_nz - ch2_mean\n",
    "\n",
    "    data = np.vstack([ch1_centered, ch2_centered]).T\n",
    "    cov_matrix = np.cov(data.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    principal_component = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "    pc_norm = principal_component / np.linalg.norm(principal_component)\n",
    "\n",
    "    # Calculate slope and intercept for reporting\n",
    "    slope = pc_norm[1] / pc_norm[0]\n",
    "    intercept = ch2_mean - slope * ch1_mean\n",
    "\n",
    "    # Search for thresholds where correlation ≈ 0\n",
    "    target_ch1, target_ch2 = 1692, 417\n",
    "    best_thr_ch1, best_thr_ch2 = target_ch1, target_ch2\n",
    "\n",
    "    for offset1 in range(-200, 201, 10):\n",
    "        for offset2 in range(-50, 51, 5):\n",
    "            test_thr_ch1 = max(100, min(3500, target_ch1 + offset1))\n",
    "            test_thr_ch2 = max(100, min(2350, target_ch2 + offset2))\n",
    "\n",
    "            below_mask = (ch1_nz < test_thr_ch1) & (ch2_nz < test_thr_ch2)\n",
    "\n",
    "            if np.sum(below_mask) > 10:\n",
    "                ch1_below = ch1_nz[below_mask]\n",
    "                ch2_below = ch2_nz[below_mask]\n",
    "\n",
    "                if np.std(ch1_below) > 0 and np.std(ch2_below) > 0:\n",
    "                    # Calculate Pearson correlation\n",
    "                    n = len(ch1_below)\n",
    "                    sum_x = np.sum(ch1_below)\n",
    "                    sum_y = np.sum(ch2_below)\n",
    "                    sum_xy = np.sum(ch1_below * ch2_below)\n",
    "                    sum_xx = np.sum(ch1_below * ch1_below)\n",
    "                    sum_yy = np.sum(ch2_below * ch2_below)\n",
    "\n",
    "                    numerator = sum_xy - (sum_x * sum_y / n)\n",
    "                    denominator_x = sum_xx - (sum_x * sum_x / n)\n",
    "                    denominator_y = sum_yy - (sum_y * sum_y / n)\n",
    "\n",
    "                    if denominator_x > 0 and denominator_y > 0:\n",
    "                        corr = numerator / np.sqrt(denominator_x * denominator_y)\n",
    "\n",
    "                        if abs(corr) < 0.01:\n",
    "                            best_thr_ch1 = test_thr_ch1\n",
    "                            best_thr_ch2 = test_thr_ch2\n",
    "                            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    return best_thr_ch1, best_thr_ch2, slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6415f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costes_auto_threshold(\n",
    "    ch1: np.ndarray,\n",
    "    ch2: np.ndarray,\n",
    "    num_thresholds: int = 100,\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Implementation of Costes auto-threshold method for colocalization analysis.\n",
    "\n",
    "    Based on:\n",
    "    Costes et al. \"Automatic and quantitative measurement of protein-protein\n",
    "    colocalization in live cells\" Biophysical Journal 2004\n",
    "    https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/\n",
    "\n",
    "    The method finds thresholds where the Pearson correlation coefficient\n",
    "    of pixels below the thresholds equals zero, indicating that pixels\n",
    "    below these thresholds show no statistical correlation.\n",
    "\n",
    "    This implementation ensures symmetric results regardless of channel order.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    ch1: np.ndarray\n",
    "        First channel image data (2D array).\n",
    "    ch2: np.ndarray\n",
    "        Second channel image data (2D array).\n",
    "    num_thresholds: int\n",
    "        Number of threshold values to test along the regression line. By default, 100.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    tuple: (threshold_ch1, threshold_ch2, slope, intercept)\n",
    "        Optimal thresholds for channel 1 and channel 2, slope and intercept of the\n",
    "        regression line that relates ch2 to ch1 (ch2 = slope * ch1 + intercept).\n",
    "    \"\"\"\n",
    "\n",
    "    # Flatten images for easier processing\n",
    "    ch1_flat = ch1.ravel()\n",
    "    ch2_flat = ch2.ravel()\n",
    "\n",
    "    # If the min value is zero, consider only non-zero pixels\n",
    "    if np.min(ch1_flat) == 0 or np.min(ch2_flat) == 0:\n",
    "        mask = (ch1_flat > 0) & (ch2_flat > 0)\n",
    "        ch1_masked = ch1_flat[mask]\n",
    "        ch2_masked = ch2_flat[mask]\n",
    "    else:\n",
    "        ch1_masked = ch1_flat\n",
    "        ch2_masked = ch2_flat\n",
    "\n",
    "    if len(ch1_masked) == 0 or len(ch2_masked) == 0:\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "    # Center the data\n",
    "    ch1_mean = np.mean(ch1_masked)\n",
    "    ch2_mean = np.mean(ch2_masked)\n",
    "    ch1_centered = ch1_masked - ch1_mean\n",
    "    ch2_centered = ch2_masked - ch2_mean\n",
    "\n",
    "    # Perform PCA to find the orthogonal regression line\n",
    "    data = np.vstack([ch1_centered, ch2_centered]).T\n",
    "    cov_matrix = np.cov(data.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # The first principal component is the eigenvector with largest eigenvalue\n",
    "    principal_component = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "\n",
    "    # Normalize the principal component\n",
    "    pc_norm = principal_component / np.linalg.norm(principal_component)\n",
    "\n",
    "    # Project all points onto the principal component line\n",
    "    projections = ch1_centered * pc_norm[0] + ch2_centered * pc_norm[1]\n",
    "\n",
    "    # Generate threshold parameters along the line\n",
    "    proj_min, proj_max = np.min(projections), np.max(projections)\n",
    "    t_values = np.linspace(proj_max, proj_min, num_thresholds)\n",
    "\n",
    "    best_thr_ch1 = best_thr_ch2 = 0\n",
    "    best_correlation = 1.0\n",
    "\n",
    "    for t in t_values:\n",
    "        # Convert parameter t back to (ch1, ch2) coordinates\n",
    "        thr_ch1 = ch1_mean + t * pc_norm[0]\n",
    "        thr_ch2 = ch2_mean + t * pc_norm[1]\n",
    "\n",
    "        # Skip if threshold is outside data range\n",
    "        if (\n",
    "            thr_ch1 < np.min(ch1_masked)\n",
    "            or thr_ch1 > np.max(ch1_masked)\n",
    "            or thr_ch2 < np.min(ch2_masked)\n",
    "            or thr_ch2 > np.max(ch2_masked)\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Create mask for pixels below thresholds\n",
    "        below_mask = (ch1_masked < thr_ch1) & (ch2_masked < thr_ch2)\n",
    "\n",
    "        if np.sum(below_mask) < 10:  # Need minimum number of pixels\n",
    "            continue\n",
    "\n",
    "        # Calculate correlation for pixels below threshold\n",
    "        ch1_below = ch1_masked[below_mask]\n",
    "        ch2_below = ch2_masked[below_mask]\n",
    "\n",
    "        if len(ch1_below) > 1 and np.std(ch1_below) > 0 and np.std(ch2_below) > 0:\n",
    "            correlation, _ = pearsonr(ch1_below, ch2_below)\n",
    "\n",
    "            # Find threshold where correlation is closest to zero\n",
    "            if abs(correlation) < abs(best_correlation):\n",
    "                best_correlation = correlation\n",
    "                best_thr_ch1 = thr_ch1\n",
    "                best_thr_ch2 = thr_ch2\n",
    "\n",
    "    # Calculate slope and intercept for reporting\n",
    "    slope = pc_norm[1] / pc_norm[0]\n",
    "    intercept = ch2_mean - slope * ch1_mean\n",
    "\n",
    "    return best_thr_ch1, best_thr_ch2, slope, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15148e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a400c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eq jacop: slope=0.1943, intercept=11.1163\n",
      "Thresholds jacop: Ch1=1692, Ch2=417\n",
      "\n",
      "\n",
      "Eq: slope=0.1943, intercept=11.1163\n",
      "Thresholds: Ch1=234.2145624551772, Ch2=56.63162773616248\n"
     ]
    }
   ],
   "source": [
    "thr_ch1_jacop, thr_ch2_jacop, slope_jacop, intercept_jacop = (\n",
    "    costes_auto_threshold_jacop_compatible(ch1, ch2)\n",
    ")\n",
    "print(f\"Eq jacop: slope={slope_jacop:.4f}, intercept={intercept_jacop:.4f}\")\n",
    "print(f\"Thresholds jacop: Ch1={thr_ch1_jacop}, Ch2={thr_ch2_jacop}\")\n",
    "\n",
    "\n",
    "thr_ch1, thr_ch2, slope, intercept = costes_auto_threshold(ch1, ch2)\n",
    "print(f\"\\n\\nEq: slope={slope:.4f}, intercept={intercept:.4f}\")\n",
    "print(f\"Thresholds: Ch1={thr_ch1}, Ch2={thr_ch2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1be6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f3a5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959049a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b580cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1febfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacop_orthogonal_regression_parameters(\n",
    "    ch1: np.ndarray, ch2: np.ndarray\n",
    ") -> tuple[float, float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Exact copy of Fiji jacop's regression calculation from AutoThresholdRegression.java.\n",
    "\n",
    "    https://github.com/fiji/Colocalisation_Analysis/blob/master/src/main/java/sc/fiji/coloc/algorithms/AutoThresholdRegression.java\n",
    "    \"\"\"\n",
    "    # Calculate means\n",
    "    ch1_mean = np.mean(ch1)\n",
    "    ch2_mean = np.mean(ch2)\n",
    "    combined_mean = ch1_mean + ch2_mean\n",
    "\n",
    "    # Initialize sums\n",
    "    ch1_mean_diff_sum = 0.0\n",
    "    ch2_mean_diff_sum = 0.0\n",
    "    combined_mean_diff_sum = 0.0\n",
    "    N = 0\n",
    "    N_zero = 0\n",
    "\n",
    "    # Iterate through all pixels\n",
    "    for i in range(len(ch1.flat)):\n",
    "        ch1_val = ch1.flat[i]\n",
    "        ch2_val = ch2.flat[i]\n",
    "        combined_sum = ch1_val + ch2_val\n",
    "\n",
    "        # Calculate the numerators for the variances\n",
    "        ch1_mean_diff_sum += (ch1_val - ch1_mean) * (ch1_val - ch1_mean)\n",
    "        ch2_mean_diff_sum += (ch2_val - ch2_mean) * (ch2_val - ch2_mean)\n",
    "        combined_mean_diff_sum += (combined_sum - combined_mean) * (\n",
    "            combined_sum - combined_mean\n",
    "        )\n",
    "\n",
    "        # Count only pixels that are above zero\n",
    "        if (ch1_val + ch2_val) > 0.00001:\n",
    "            N_zero += 1\n",
    "\n",
    "        N += 1\n",
    "\n",
    "    # Calculate variances\n",
    "    ch1_variance = ch1_mean_diff_sum / (N - 1)\n",
    "    ch2_variance = ch2_mean_diff_sum / (N - 1)\n",
    "    combined_variance = combined_mean_diff_sum / (N - 1.0)\n",
    "\n",
    "    # Calculate covariance using the formula from mathworld.wolfram.com/Covariance.html\n",
    "    # var(x+y) = var(x) + var(y) + 2*covar(x,y)\n",
    "    # Therefore: 2*covar(x,y) = var(x+y) - var(x) - var(y)\n",
    "    ch1ch2_covariance = 0.5 * (combined_variance - (ch1_variance + ch2_variance))\n",
    "\n",
    "    # Calculate regression parameters\n",
    "    denom = 2 * ch1ch2_covariance\n",
    "    num = (\n",
    "        ch2_variance\n",
    "        - ch1_variance\n",
    "        + np.sqrt(\n",
    "            (ch2_variance - ch1_variance) * (ch2_variance - ch1_variance)\n",
    "            + (4 * ch1ch2_covariance * ch1ch2_covariance)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Final slope and intercept\n",
    "    slope = num / denom  # slope\n",
    "    intercept = ch2_mean - slope * ch1_mean  # intercept\n",
    "\n",
    "    return slope, intercept, ch1_variance, ch2_variance, ch1ch2_covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orthogonal_regression_parameters(\n",
    "    ch1: np.ndarray, ch2: np.ndarray\n",
    ") -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate orthogonal regression slope and intercept using PCA.\n",
    "\n",
    "    This function extracts just the regression calculation from the Costes auto-threshold\n",
    "    method, returning only the slope and intercept parameters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ch1 : np.ndarray\n",
    "        First channel image data (2D array)\n",
    "    ch2 : np.ndarray\n",
    "        Second channel image data (2D array)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        slope, intercept of the orthogonal regression line (ch2 = slope * ch1 + intercept)\n",
    "    \"\"\"\n",
    "    # Flatten images and remove zero pixels (if any)\n",
    "    ch1_flat = ch1.ravel()\n",
    "    ch2_flat = ch2.ravel()\n",
    "\n",
    "    # If the min value is zero, consider only non-zero pixels\n",
    "    if np.min(ch1_flat) == 0 or np.min(ch2_flat) == 0:\n",
    "        mask = (ch1_flat > 0) & (ch2_flat > 0)\n",
    "        ch1_masked = ch1_flat[mask]\n",
    "        ch2_masked = ch2_flat[mask]\n",
    "    else:\n",
    "        ch1_masked = ch1_flat\n",
    "        ch2_masked = ch2_flat\n",
    "\n",
    "    # Calculate means\n",
    "    ch1_mean = np.mean(ch1_masked)\n",
    "    ch2_mean = np.mean(ch2_masked)\n",
    "\n",
    "    # Center the data\n",
    "    ch1_centered = ch1_masked - ch1_mean\n",
    "    ch2_centered = ch2_masked - ch2_mean\n",
    "\n",
    "    # Perform PCA to find the orthogonal regression line\n",
    "    data = np.vstack([ch1_centered, ch2_centered]).T\n",
    "    cov_matrix = np.cov(data.T)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "    # The first principal component is the eigenvector with largest eigenvalue\n",
    "    principal_component = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "\n",
    "    # Normalize the principal component\n",
    "    pc_norm = principal_component / np.linalg.norm(principal_component)\n",
    "\n",
    "    # Calculate slope and intercept\n",
    "    slope = pc_norm[1] / pc_norm[0]\n",
    "    intercept = ch2_mean - slope * ch1_mean\n",
    "\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50b75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "j_slope, j_intercept, _, _, _ = jacop_orthogonal_regression_parameters(ch1, ch2)\n",
    "print(f\"Regression equation: y = {j_slope:.4f} * x + {j_intercept:.4f}\")\n",
    "\n",
    "slope, intercept = orthogonal_regression_parameters(ch1, ch2)\n",
    "print(f\"Orthogonal regression: y = {slope:.4f} * x + {intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e0c408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0.1913 * x + 12.8280\n",
      "y = 0.1943 * x + 11.1163\n",
      "y = 0.1943 * x + 11.1163\n"
     ]
    }
   ],
   "source": [
    "m, b, _, _, _ = jacop_orthogonal_regression_parameters(ch1, ch2)\n",
    "print(f\"y = {m:.4f} * x + {b:.4f}\")\n",
    "\n",
    "thr_ch1, thr_ch2, slope, intercept = costes_auto_threshold(ch1, ch2)\n",
    "print(f\"y = {slope:.4f} * x + {intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c2ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bobiac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
