{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e296f4b",
   "metadata": {},
   "source": [
    "# Mander's Correlation Coefficients\n",
    "\n",
    "<div class=\"custom-button-row\">\n",
    "    <a \n",
    "        class=\"custom-button custom-download-button\" href=\"../../../notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" download>\n",
    "        <i class=\"fas fa-download\"></i> Download this Notebook\n",
    "    </a>\n",
    "    <a\n",
    "    class=\"custom-button custom-download-button\" href=\"https://colab.research.google.com/github/HMS-IAC/bobiac/blob/gh-pages/colab_notebooks/08_colocalization/pixel_intensity_based_colocalization_manders.ipynb\" target=\"_blank\">\n",
    "        <img class=\"button-icon\" src=\"../../../_static/logo/icon-google-colab.svg\" alt=\"Open in Colab\">\n",
    "        Open in Colab\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /// script\n",
    "# requires-python = \">=3.12\"\n",
    "# dependencies = [\n",
    "#     \"matplotlib\",\n",
    "#     \"ndv[jupyter,vispy]\",\n",
    "#     \"scikit-image\",\n",
    "#     \"numpy\",\n",
    "#     \"scipy\",\n",
    "#     \"tifffile\",\n",
    "#     \"imagecodecs\",\n",
    "#     \"tqdm\",\n",
    "# ]\n",
    "# ///"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadc72aa",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook, we will explore how to implement **Mander's Correlation Coefficients** in Python, a common method for quantifying colocalization based on pixel intensities.\n",
    "\n",
    "The images we will use for this section can be downloaded from the <a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Mander's & Pearson's Colocalization Dataset</a>.\n",
    "\n",
    "<p class=\"alert alert-warning\">\n",
    "   <strong>Note:</strong> This notebook aims to show how to practically implement these methods but does not aim to describe when to use this method. The images used have been selected to showcase the practical implementation of the methods.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> In this example, we will not perform any image processing steps before computing the Mander's Correlation Coefficients. However, when conducting a real colocalization analysis, you should consider applying some image processing steps to clean the images before computing the Mander's Correlation Coefficients, such as background subtraction, flat-field correction, etc.\n",
    "</p>\n",
    "\n",
    "<p class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> In this notebook, we will only use a single image pair for demonstration purposes. Often, Mander's coefficients should not be interpreted as absolute values in isolation. Instead, it's always recommended to consider them in the context of comparisons between different conditions, controls, treatments, or experimental groups. The relative changes and ratios between conditions are often more meaningful than the absolute coefficient values themselves.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1dd28d",
   "metadata": {},
   "source": [
    "## Mander's Correlation Coefficients\n",
    "\n",
    "Mander's correlation coefficients can be used to quantify the degree of colocalization between two channels (or images). These coefficients, M1 and M2, are calculated based on the pixel intensities of the two channels and for this reason, they are different from a simple area overlap.\n",
    "\n",
    "**M1** measures the **fraction of channel 1 intensity that co-occurs with channel 2**:\n",
    "- **Numerator**: Sum of channel 1 intensities in pixels where both channels are above their thresholds\n",
    "- **Denominator**: Sum of all channel 1 intensities above threshold\n",
    "\n",
    "**M2** measures the **fraction of channel 2 intensity that co-occurs with channel 1**:\n",
    "- **Numerator**: Sum of channel 2 intensities in pixels where both channels are above their thresholds\n",
    "- **Denominator**: Sum of all channel 2 intensities above threshold\n",
    "\n",
    "<div> <img src=\"https://raw.githubusercontent.com/HMS-IAC/bobiac/main/_static/images/coloc/manders_slide.png\" alt=\"manders\" width=\"800\"></div>\n",
    "\n",
    "For this exercise, we will analyze an image of a HeLa cell stained with two fluorescent markers: **channel 1** labels **endosomes** and **channel 2** labels **lysosomes** (<a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i>Mander's & Pearson's Colocalization Dataset</a>.)\n",
    "\n",
    "From a biological perspective, lysosomes are typically found within or closely associated with endosomal compartments, while endosomes have a broader cellular distribution. Based on this biology, we expect:\n",
    "\n",
    "- **High M2 coefficient**: Most lysosomal signal should colocalize with endosomal regions\n",
    "- **Lower M1 coefficient**: Only a subset of endosomal signal should colocalize with lysosomes, since endosomes are more widely distributed throughout the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f616961",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724dea6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ndv\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.stats import pearsonr\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef6900a",
   "metadata": {},
   "source": [
    "### Load and Visualize the Image\n",
    "\n",
    "Open and visualize (with ndv) the image named `cells_manders_14na.tif` from the <a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download><i class=\"fas fa-download\"></i> Mander's & Pearson's Colocalization Dataset</a>. This is a two-channel image where channel 1 has stained endosomes and channel 2 has stained lysosomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58157086",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Open the image\n",
    "img_path = \"../../_static/images/coloc/cells_manders_14na.tif\"\n",
    "img = tifffile.imread(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca3d02",
   "metadata": {
    "tags": [
     "skip-execution",
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Visualize the image\n",
    "ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea13af",
   "metadata": {
    "tags": [
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "viewer = ndv.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bc0d3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.widget().children[1].snapshot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98764c14",
   "metadata": {},
   "source": [
    "To compute Mander's Correlation Coefficients, we need **two separate images** (channels). \n",
    "\n",
    "What is the image shape? How do we split the channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86327fbe",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get image shape\n",
    "print(\"Image shape:\", img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9bf352",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Split the image into channels\n",
    "ch1 = img[0]\n",
    "ch2 = img[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc303e",
   "metadata": {},
   "source": [
    "### Calculate Numerators and Denominators for Mander's Correlation Coefficients\n",
    "\n",
    "The first and key step is to calculate **$R_i^{}$** and **$G_i^{}$** and thus to select which areas of each channel we want to consider for the colocalization analysis. This means we first need to **threshold each images to select only the pixels we want to consider**.\n",
    "\n",
    "It is therefore evident that Mander's Correlation Coefficients are **sensitive to thresholding**, the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "For this example, we will first use a simple Otsu thresholding method and later in the notebook we will explore a more automated way of selecting the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d3aa1",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > threshold_otsu(ch1)\n",
    "image_2_mask = ch2 > threshold_otsu(ch2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642f375",
   "metadata": {},
   "source": [
    "We can plot the raw data and the masks in a 2x2 subplot to visualize the results of the thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7526f6cb",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fce32fb",
   "metadata": {},
   "source": [
    "Now that we have the mask for each channel, we can first **calculate the overlap mask** where both channels are above their respective thresholds, and then calculate **$R_i^{coloc}$** and **$G_i^{coloc}$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81202e9",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask using a logical AND operation\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3076eb",
   "metadata": {},
   "source": [
    "With the overlap mask, we can now calculate the **$R_i^{coloc}$** (*ch1_coloc*) and **$G_i^{coloc}$** (*ch2_coloc*) and the **numerator** for the Mander's Correlation Coefficients: **sum($R_i^{coloc}$)** and **sum($G_i^{coloc}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103976dd",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce9ff23",
   "metadata": {},
   "source": [
    "We can now **calculate the denominator** for the Manders coefficients.\n",
    "<br>\n",
    "The denominator is the sum of the pixel intensities in the overlap mask for each channel above their respective thresholds: **sum($R_i^{}$)** and **sum($G_i^{}$)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085491bf",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eaf3fb",
   "metadata": {},
   "source": [
    "### Calculate Mander's Correlation Coefficients\n",
    "\n",
    "Now with both numerators and denominators calculated, we can compute the Manders coefficients M1 and M2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ccf24f",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.4f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b68b8",
   "metadata": {},
   "source": [
    "With Otsu thresholding for both channels, we obtain:\n",
    "\n",
    "**M1=0.3496** and **M2=0.8975**\n",
    "\n",
    "- **M1** indicates that approximately **35%** (0.3496) of channel 1's intensity colocalizes with channel 2. This means that about one-third of channel 1's signal overlaps with areas where channel 2 is also present above threshold.\n",
    "\n",
    "- **M2** indicates that approximately **90%** (0.8975) of channel 2's intensity colocalizes with channel 1. This suggests that nearly all of channel 2's signal overlaps with areas where channel 1 is also present above threshold.\n",
    "\n",
    "This asymmetry (M1 ≠ M2) is common and tells us that **channel 2 is largely contained within areas where channel 1 is present**, but **channel 1 extends beyond the regions where channel 2 is found**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12baf806",
   "metadata": {},
   "source": [
    "**Bonus**\n",
    "\n",
    "In the <a href=\"../../../_static/data/08_pixel_intensity_based_coloc.zip\" download> <i class=\"fas fa-download\"></i> Mander's & Pearson's Colocalization Dataset</a> there is an image named `cells_manders_0.3na.tif`, the exact same image we just used nut acquired with a smaller numerical aperture (NA) of the objective lens.\n",
    "\n",
    "What do you think will happen to the Mander's coefficients if we use this image instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fedfc5",
   "metadata": {},
   "source": [
    "### Costes Auto-Threshold Method\n",
    "\n",
    "As mentioned above, the Mender's Correlation Coefficients are sensitive to thresholding, so the way you decide to threshold your images will have a large impact on the results.\n",
    "\n",
    "The function `costes_auto_threshold` below implements the [Costes auto-threshold method](https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/), which **automatically determines optimal threshold values for both channels**. \n",
    "\n",
    "The method works by finding threshold values where pixels *below* these thresholds show no statistical correlation (Pearson correlation coefficient ≈ 0). This approach helps objectively separate true signal from background noise.\n",
    "\n",
    "The algorithm performs orthogonal linear regression between the two channels to establish their relationship, then iteratively tests threshold pairs derived from this regression to identify the optimal separation point between signal and background.\n",
    "\n",
    "Of course, the Costes auto-threshold method has limitations and may not work in certain scenarios, including:\n",
    "- **Insufficient data**: When there are too few non-zero pixels (< 10) in either channel\n",
    "- **No linear relationship**: When channels show non-linear, multiple population, or no correlation patterns.\n",
    "- **Low variance**: When one or both channels have uniform or near-uniform intensities\n",
    "- **High background noise**: When noise dominates the signal relationship\n",
    "- **Limited dynamic range**: Narrow intensity ranges or saturated pixels\n",
    "\n",
    "In such cases, alternative thresholding methods (Otsu, manual, percentile-based) may be more appropriate.\n",
    "\n",
    "We can now try to compute the Mander's Correlation Coefficients using the Costes auto-threshold method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04775d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costes_auto_threshold(\n",
    "    ch1: np.ndarray,\n",
    "    ch2: np.ndarray,\n",
    "    num_thresholds: int = 100,\n",
    ") -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Implementation of Costes auto-threshold method for colocalization analysis.\n",
    "\n",
    "    Based on:\n",
    "    Costes et al. \"Automatic and quantitative measurement of protein-protein\n",
    "    colocalization in live cells\" Biophysical Journal 2004\n",
    "    https://pmc.ncbi.nlm.nih.gov/articles/PMC1304300/\n",
    "\n",
    "    The method finds thresholds where the Pearson correlation coefficient\n",
    "    of pixels below the thresholds equals zero, indicating that pixels\n",
    "    below these thresholds show no statistical correlation.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    ch1: np.ndarray\n",
    "        First channel image data (2D array).\n",
    "    ch2: np.ndarray\n",
    "        Second channel image data (2D array).\n",
    "    num_thresholds: int\n",
    "        Number of threshold values to test along the regression line. By default, 100.\n",
    "\n",
    "    Returns\n",
    "    ------\n",
    "    tuple: (threshold_ch1, threshold_ch2, slope, intercept)\n",
    "        Optimal thresholds for channel 1 and channel 2, slope and intercept of the\n",
    "        regression line that relates the two channels.\n",
    "    \"\"\"\n",
    "\n",
    "    def orthogonal_regression(x, y):\n",
    "        \"\"\"Perform orthogonal regression using PCA\"\"\"\n",
    "        # Center the data\n",
    "        x_centered = x - np.mean(x)\n",
    "        y_centered = y - np.mean(y)\n",
    "\n",
    "        # Stack data for PCA\n",
    "        data = np.vstack([x_centered, y_centered]).T\n",
    "\n",
    "        # Compute covariance matrix\n",
    "        cov_matrix = np.cov(data.T)\n",
    "\n",
    "        # Get eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "        # The first principal component is the eigenvector with largest eigenvalue\n",
    "        principal_component = eigenvectors[:, np.argmax(eigenvalues)]\n",
    "\n",
    "        # Get slope from first principal component\n",
    "        slope = principal_component[1] / principal_component[0]\n",
    "        intercept = np.mean(y) - slope * np.mean(x)\n",
    "\n",
    "        return slope, intercept\n",
    "\n",
    "    # Flatten images for easier processing\n",
    "    ch1_flat = ch1.flatten()\n",
    "    ch2_flat = ch2.flatten()\n",
    "\n",
    "    # If the min value is zero, consider only non-zero pixels\n",
    "    if np.min(ch1_flat) == 0 or np.min(ch2_flat) == 0:\n",
    "        mask = (ch1_flat > 0) & (ch2_flat > 0)\n",
    "        ch1_masked = ch1_flat[mask]\n",
    "        ch2_masked = ch2_flat[mask]\n",
    "    else:\n",
    "        ch1_masked = ch1_flat\n",
    "        ch2_masked = ch2_flat\n",
    "\n",
    "    if len(ch1_masked) == 0 or len(ch2_masked) == 0:\n",
    "        return 0, 0, 0, 0\n",
    "\n",
    "    # Perform orthogonal regression to find the relationship between channels\n",
    "    # This gives us the line IG = a * IR + b using orthogonal regression as per Costes paper\n",
    "    slope, intercept = orthogonal_regression(ch1_masked, ch2_masked)\n",
    "\n",
    "    # Create threshold pairs along the regression line\n",
    "    # Choose iteration strategy based on slope and dynamic range for better numerical stability\n",
    "    max_ch1, max_ch2 = np.max(ch1_masked), np.max(ch2_masked)\n",
    "    min_ch1, min_ch2 = np.min(ch1_masked), np.min(ch2_masked)\n",
    "\n",
    "    range_ch1 = max_ch1 - min_ch1\n",
    "    range_ch2 = max_ch2 - min_ch2\n",
    "\n",
    "    best_thr_ch1 = best_thr_ch2 = 0\n",
    "    best_correlation = 1.0\n",
    "\n",
    "    # Choose which channel to iterate over based on:\n",
    "    # 1. Slope magnitude (for numerical stability)\n",
    "    # 2. Dynamic range (for better sampling)\n",
    "    use_ch1_as_driver = True\n",
    "\n",
    "    # Is the slope steep, iterate over ch2 for stability\n",
    "    if abs(slope) > 1.5:\n",
    "        use_ch1_as_driver = False\n",
    "    # Elif slope is shallow, iterate over ch1 for stability\n",
    "    elif abs(slope) < 0.67:\n",
    "        use_ch1_as_driver = True\n",
    "    # Otherwise use channel with larger range dynamic range\n",
    "    else:\n",
    "        use_ch1_as_driver = range_ch1 >= range_ch2\n",
    "\n",
    "    if use_ch1_as_driver:\n",
    "        # Iterate over ch1 thresholds, calculate ch2 from regression\n",
    "        threshold_values = np.linspace(max_ch1, min_ch1, num_thresholds)\n",
    "\n",
    "        for thr_ch1 in threshold_values:\n",
    "            thr_ch2 = slope * thr_ch1 + intercept\n",
    "\n",
    "            # Create mask for pixels below thresholds\n",
    "            below_mask = (ch1_masked < thr_ch1) & (ch2_masked < thr_ch2)\n",
    "\n",
    "            if np.sum(below_mask) < 10:  # Need minimum number of pixels\n",
    "                continue\n",
    "\n",
    "            # Calculate correlation for pixels below threshold\n",
    "            ch1_below = ch1_masked[below_mask]\n",
    "            ch2_below = ch2_masked[below_mask]\n",
    "\n",
    "            if len(ch1_below) > 1 and np.std(ch1_below) > 0 and np.std(ch2_below) > 0:\n",
    "                correlation, _ = pearsonr(ch1_below, ch2_below)\n",
    "\n",
    "                # Find threshold where correlation is closest to zero\n",
    "                if abs(correlation) < abs(best_correlation):\n",
    "                    best_correlation = correlation\n",
    "                    best_thr_ch1 = thr_ch1\n",
    "                    best_thr_ch2 = thr_ch2\n",
    "\n",
    "    else:\n",
    "        # Iterate over ch2 thresholds, calculate ch1 from regression\n",
    "        threshold_values = np.linspace(max_ch2, min_ch2, num_thresholds)\n",
    "\n",
    "        for thr_ch2 in threshold_values:\n",
    "            # Solve for ch1: ch1 = (ch2 - intercept) / slope\n",
    "            if abs(slope) > 1e-10:  # Avoid division by zero\n",
    "                thr_ch1 = (thr_ch2 - intercept) / slope\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Create mask for pixels below thresholds\n",
    "            below_mask = (ch1_masked < thr_ch1) & (ch2_masked < thr_ch2)\n",
    "\n",
    "            if np.sum(below_mask) < 10:  # Need minimum number of pixels\n",
    "                continue\n",
    "\n",
    "            # Calculate correlation for pixels below threshold\n",
    "            ch1_below = ch1_masked[below_mask]\n",
    "            ch2_below = ch2_masked[below_mask]\n",
    "\n",
    "            if len(ch1_below) > 1 and np.std(ch1_below) > 0 and np.std(ch2_below) > 0:\n",
    "                correlation, _ = pearsonr(ch1_below, ch2_below)\n",
    "\n",
    "                # Find threshold where correlation is closest to zero\n",
    "                if abs(correlation) < abs(best_correlation):\n",
    "                    best_correlation = correlation\n",
    "                    best_thr_ch1 = thr_ch1\n",
    "                    best_thr_ch2 = thr_ch2\n",
    "\n",
    "    return best_thr_ch1, best_thr_ch2, slope, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f792a0a6",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "source": [
    "### Calculate Mander's Coefficients with Costes Auto-Thresholds\n",
    "\n",
    "Calculate the Costes auto-thresholds for the two channels and print the thresholds.\n",
    "\n",
    "**Bonus:**\n",
    "<br>\n",
    "Also plot a scatter plot of the two channels with the linear regression line.\n",
    "<br>\n",
    "Note that the `costes_auto_threshold` function returns (in order) *Costes thresholds for channel 1*, *Costes thresholds for channel 2*, *slope* and *intercept* of the linear regression. We can use the slope and intercept to plot the linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c817765",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate Costes auto-thresholds for the two channels\n",
    "costes_thr_ch1, costes_thr_ch2, slope, intercept = costes_auto_threshold(ch1, ch2)\n",
    "print(\n",
    "    \"Costes thresholds:\\n\"\n",
    "    f\"Channel 1 = {costes_thr_ch1}\\n\"\n",
    "    f\"Channel 2 = {costes_thr_ch2}\\n\"\n",
    "    f\"Regression Eq: y = {slope:.4f} * x + {intercept:.4f}\"\n",
    ")\n",
    "\n",
    "# plot scatter plot of the two channels with thresholds\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(ch1.flatten(), ch2.flatten(), s=1, alpha=0.5)\n",
    "plt.axvline(costes_thr_ch1, color=\"green\", linestyle=\"--\", label=\"Threshold ch1\")\n",
    "plt.axhline(costes_thr_ch2, color=\"magenta\", linestyle=\"--\", label=\"Threshold ch2\")\n",
    "x_vals = np.unique(ch1.flatten())  # Get unique intensity values from ch1\n",
    "y_vals = slope * x_vals + intercept\n",
    "plt.plot(\n",
    "    x_vals, y_vals, color=\"k\", linestyle=\"--\", label=\"Regression line\", linewidth=2\n",
    ")\n",
    "plt.xlabel(\"Channel 1 Intensity\")\n",
    "plt.ylabel(\"Channel 2 Intensity\")\n",
    "plt.title(\"Costes Auto-Threshold Scatter Plot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8604302",
   "metadata": {},
   "source": [
    "Now that we have the Costes thresholds, we can calculate the Mander's Correlation Coefficients using the Costes thresholds as we did for the Otsu thresholds.\n",
    "\n",
    "How do thresholds and mask images compare to the Otsu thresholds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b35b8",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Create binary masks based on thresholds\n",
    "image_1_mask = ch1 > costes_thr_ch1\n",
    "image_2_mask = ch2 > costes_thr_ch2\n",
    "\n",
    "# Plot raw data and masks in a 2x2 subplot\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "# Raw channel 1\n",
    "im1 = ax[0, 0].imshow(ch1)\n",
    "ax[0, 0].set_title(\"Channel 1 (Raw Data)\")\n",
    "ax[0, 0].axis(\"off\")\n",
    "plt.colorbar(im1, ax=ax[0, 0], fraction=0.045)\n",
    "# Raw channel 2\n",
    "im2 = ax[0, 1].imshow(ch2)\n",
    "ax[0, 1].set_title(\"Channel 2 (Raw Data)\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "plt.colorbar(im2, ax=ax[0, 1], fraction=0.045)\n",
    "# Channel 1 mask\n",
    "ax[1, 0].imshow(image_1_mask)\n",
    "ax[1, 0].set_title(\"Channel 1 Mask\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "# Channel 2 mask\n",
    "ax[1, 1].imshow(image_2_mask)\n",
    "ax[1, 1].set_title(\"Channel 2 Mask\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87520e4",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the overlap mask\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Plot overlap mask\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(overlap_mask)\n",
    "plt.title(\"Overlap Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccc9b2",
   "metadata": {
    "tags": [
     "teacher"
    ]
   },
   "outputs": [],
   "source": [
    "# Numerator\n",
    "# Extract intensity from channel 1 only at pixels where both channels overlap\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "# Extract intensity from channel 2 only at pixels where both channels overlap\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Calculate the numerator for the Manders coefficients\n",
    "m1_numerator = np.sum(ch1_coloc)\n",
    "m2_numerator = np.sum(ch2_coloc)\n",
    "\n",
    "# Denominator\n",
    "# Calculate the sum of the intensities in channel 1 and channel 2 above their\n",
    "# respective thresholds\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "m1_denominator = np.sum(ch1_tr)\n",
    "m2_denominator = np.sum(ch2_tr)\n",
    "\n",
    "# Calculate the Manders coefficients\n",
    "M1 = m1_numerator / m1_denominator\n",
    "M2 = m2_numerator / m2_denominator\n",
    "\n",
    "print(f\"Manders coefficient M1: {M1:.4f}\")\n",
    "print(f\"Manders coefficient M2: {M2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28be7657",
   "metadata": {},
   "source": [
    "### Image Translation Randomization Test\n",
    "\n",
    "The **image translation randomization** test is a statistical method used to **validate the significance of colocalization results**, particularly for Mander's coefficients. This method involves **randomly translating one channel relative to another and recalculating the Mander's coefficients** to create a distribution of values under the null hypothesis of no colocalization.\n",
    "\n",
    "Below you can find an implementation of this method in Python. This function returns the Mander's coefficients, the random Mander's coefficients, and the p-values for both coefficients.\n",
    "\n",
    "A low `p-value` (e.g. 0.0001) means that none of the `n` random translations (by default 1000) produced M1/M2 values as high as the observed values without translation, indicating that the observed colocalization is statistically significant: the probability of getting the observed colocalization by random chance is < 0.0001 (less than 0.01%).\n",
    "\n",
    "Let's run it on the two channels we have been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_translation_randomization(\n",
    "    channel_1: np.ndarray,\n",
    "    channel_2: np.ndarray,\n",
    "    threshold_ch1: float = 0.0,\n",
    "    threshold_ch2: float = 0.0,\n",
    "    n_iterations: int = 1000,\n",
    "    max_shift_fraction: float = 0.5,\n",
    "    seed: int = 3,\n",
    ") -> tuple[float, float, list[float], list[float], float, float]:\n",
    "    \"\"\"\n",
    "    Perform image translation randomization test for Manders' coefficients validation.\n",
    "\n",
    "    This method applies random translations (shifts) to one channel relative to the other,\n",
    "    breaking spatial relationships while preserving intensity distributions and local patterns.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    channel_1 : np.ndarray\n",
    "        First fluorescent channel (kept fixed)\n",
    "    channel_2 : np.ndarray\n",
    "        Second fluorescent channel (will be translated)\n",
    "    threshold_ch1 : float, optional\n",
    "        Intensity threshold for channel A (if None, uses Otsu's method)\n",
    "    threshold_ch2 : float, optional\n",
    "        Intensity threshold for channel B (if None, uses Otsu's method)\n",
    "    n_iterations : int\n",
    "        Number of randomization iterations (default: 1000)\n",
    "    max_shift_fraction : float\n",
    "        Maximum shift as fraction of image dimensions (default: 0.5)\n",
    "    seed : int\n",
    "        Random numpy seed for reproducibility (default: 3)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple containing:\n",
    "        - List[float]: M1 coefficients from randomized iterations (A overlap with B)\n",
    "        - List[float]: M2 coefficients from randomized iterations (B overlap with A)\n",
    "        - float: Observed M1 coefficient\n",
    "        - float: Observed M2 coefficient\n",
    "        - float: P-value for M1 (fraction of random M1 >= observed M1)\n",
    "        - float: P-value for M2 (fraction of random M2 >= observed M2)\n",
    "    \"\"\"\n",
    "\n",
    "    # Set numpy random seed for reproducibility\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    def _calculate_manders(\n",
    "        ch1: np.ndarray, ch2: np.ndarray, thresh_ch1: float, thresh_ch2: float\n",
    "    ) -> tuple[float, float]:\n",
    "        \"\"\"Helper function to calculate Manders' correlations coefficients.\"\"\"\n",
    "        # Apply thresholds and get overlap mask\n",
    "        mask_a = ch1 > thresh_ch1\n",
    "        mask_b = ch2 > thresh_ch2\n",
    "        overlap_mask = mask_a & mask_b\n",
    "\n",
    "        # Calculate M1: fraction of A overlapping with B\n",
    "        m1_numerator = np.sum(ch1[overlap_mask])\n",
    "        m1_denominator = np.sum(ch1[mask_a])\n",
    "        m1 = m1_numerator / m1_denominator if m1_denominator > 0 else 0.0\n",
    "\n",
    "        # Calculate M2: fraction of B overlapping with A\n",
    "        m2_numerator = np.sum(ch2[overlap_mask])\n",
    "        m2_denominator = np.sum(ch2[mask_b])\n",
    "        m2 = m2_numerator / m2_denominator if m2_denominator > 0 else 0.0\n",
    "\n",
    "        return m1, m2\n",
    "\n",
    "    def _translate_image(image: np.ndarray, shift_y: int, shift_x: int) -> np.ndarray:\n",
    "        \"\"\"Translate image by given shifts with wrap-around.\"\"\"\n",
    "        return np.roll(np.roll(image, shift_y, axis=0), shift_x, axis=1)\n",
    "\n",
    "    # Calculate observed Manders' coefficients\n",
    "    observed_m1, observed_m2 = _calculate_manders(\n",
    "        channel_1, channel_2, threshold_ch1, threshold_ch2\n",
    "    )\n",
    "\n",
    "    # Calculate maximum shifts\n",
    "    max_shift_y = int(channel_2.shape[0] * max_shift_fraction)\n",
    "    max_shift_x = int(channel_2.shape[1] * max_shift_fraction)\n",
    "\n",
    "    # Initialize lists to store randomized coefficients\n",
    "    random_m1_values = []\n",
    "    random_m2_values = []\n",
    "\n",
    "    # for _ in tqdm(range(n_iterations), desc=\"Image translation randomization\"):\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random shifts (excluding zero shift)\n",
    "        shift_y = np.random.randint(-max_shift_y, max_shift_y + 1)\n",
    "        shift_x = np.random.randint(-max_shift_x, max_shift_x + 1)\n",
    "\n",
    "        # Ensure at least one shift is non-zero\n",
    "        if shift_y == 0 and shift_x == 0:\n",
    "            shift_y = np.random.choice([-1, 1])\n",
    "\n",
    "        # Apply translation to channel B\n",
    "        translated_ch2 = _translate_image(channel_2, shift_y, shift_x)\n",
    "\n",
    "        # Calculate Manders' coefficients with translated channel B\n",
    "        random_m1, random_m2 = _calculate_manders(\n",
    "            channel_1, translated_ch2, threshold_ch1, threshold_ch2\n",
    "        )\n",
    "        random_m1_values.append(random_m1)\n",
    "        random_m2_values.append(random_m2)\n",
    "\n",
    "    # Calculate p-values\n",
    "    p_value_m1 = np.sum(np.array(random_m1_values) >= observed_m1) / n_iterations\n",
    "    p_value_m2 = np.sum(np.array(random_m2_values) >= observed_m2) / n_iterations\n",
    "\n",
    "    return (\n",
    "        observed_m1,\n",
    "        observed_m2,\n",
    "        random_m1_values,\n",
    "        random_m2_values,\n",
    "        p_value_m1,\n",
    "        p_value_m2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169660a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_1, thr_2 = threshold_otsu(ch1), threshold_otsu(ch2)\n",
    "# thr_1, thr_2, _, _ = costes_auto_threshold(ch1, ch2)\n",
    "\n",
    "values = image_translation_randomization(ch1, ch2, thr_1, thr_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dc1dd3",
   "metadata": {},
   "source": [
    "We can now print the results of the analysis: M1, M2, and their respective p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c24fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "M1, M2, random_m1_values, random_m2_values, p_value_m1, p_value_m2 = values\n",
    "print(f\"M1: {M1:.4f}, p-value: {p_value_m1:.4f}\")\n",
    "print(f\"M2: {M2:.4f}, p-value: {p_value_m2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744c4eb5",
   "metadata": {},
   "source": [
    "**Bonus:**\n",
    "\n",
    "We can also visualize the distribution of the random M1 and M2 values using histograms. This will help us understand the significance of our observed values in the context of the random distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb4864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distribution of random M1 and M2 values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(random_m1_values, bins=50, color=\"magenta\", alpha=0.7, label=\"Random M1\")\n",
    "plt.axvline(M1, color=\"k\", linestyle=\"--\", label=\"Observed M1\")\n",
    "plt.xlabel(\"M1 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M1 Values\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_m2_values, bins=50, color=\"green\", alpha=0.7, label=\"Random M2\")\n",
    "plt.axvline(M2, color=\"k\", linestyle=\"--\", label=\"Observed M2\")\n",
    "plt.xlabel(\"M2 Values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Random M2 Values\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637a0cb5",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The Python implementation for calculating Mander's Correlation Coefficients is straightforward and concise, as demonstrated in the code below.\n",
    "\n",
    "```python\n",
    "# Create binary mask for channel 1 & 2 using a thresholding method of choice\n",
    "threshold_ch1, threshold_ch2 = threshold_method(ch1, ch2)\n",
    "image_1_mask = ch1 > threshold_ch1\n",
    "image_2_mask = ch2 > threshold_ch2\n",
    "\n",
    "# Find pixels that are above threshold in both channels\n",
    "overlap_mask = image_1_mask & image_2_mask\n",
    "\n",
    "# Extract channel 1 & 2 intensities only from overlapping regions\n",
    "ch1_coloc = ch1[overlap_mask]\n",
    "ch2_coloc = ch2[overlap_mask]\n",
    "\n",
    "# Extract all channel 1 & 2 intensities above threshold\n",
    "ch1_tr = ch1[image_1_mask]\n",
    "ch2_tr = ch2[image_2_mask]\n",
    "\n",
    "# Calculate total intensity of channel 1 & 2 above threshold\n",
    "sum_ch1_tr = np.sum(ch1_tr)\n",
    "sum_ch2_tr = np.sum(ch2_tr)\n",
    "\n",
    "# M1: fraction of channel 1 intensity that colocalizes with channel 2\n",
    "M1 = np.sum(ch1_coloc) / sum_ch1_tr\n",
    "# M2: fraction of channel 2 intensity that colocalizes with channel 1\n",
    "M2 = np.sum(ch2_coloc) / sum_ch2_tr\n",
    "```\n",
    "\n",
    "**Key Considerations for Mander's Correlation Analysis:**\n",
    "\n",
    "1. **Threshold Sensitivity**: Mander's coefficients are **highly sensitive to thresholding methods**. The choice of thresholding strategy will significantly impact your results, making careful threshold selection essential for accurate colocalization analysis. Consider using:\n",
    "   - **Automated thresholding methods** (like Costes auto-threshold): these are fully automated and don't require you to select or tune any parameters\n",
    "   - **Threshold calculation algorithms** (like Otsu, Li, Triangle, Yen, etc.): these automatically calculate a threshold value, but you need to choose which algorithm to use based on your image characteristics and how the resulting threshold looks\n",
    "   - **Consistent thresholding**: use the same thresholding approach across experimental conditions\n",
    "\n",
    "2. **Background Considerations**: sometimes it is necessary to apply appropriate image preprocessing steps before calculating Mander's coefficients such as Background subtraction to remove non-specific signal or Flat-field correction to account for illumination variations.\n",
    "\n",
    "3. **Statistical Validation**: always validate your results using statistical tests such as the image translation randomization test demonstrated above. This helps assess whether observed colocalization is statistically significant or could have occurred by chance.\n",
    "\n",
    "4. **Comparative Analysis**: Mander's coefficients should not be interpreted as absolute values in isolation. Instead, consider them in the context of:\n",
    "   - Comparisons between different experimental conditions\n",
    "   - Control vs. treatment groups\n",
    "   - Different time points or developmental stages\n",
    "   - Relative changes between conditions are often more meaningful than absolute values\n",
    "\n",
    "5. **Asymmetry Interpretation**: remember that M1 ≠ M2 is common and biologically meaningful.\n",
    "   - **M1**: Fraction of channel 1 intensity that overlaps with channel 2\n",
    "   - **M2**: Fraction of channel 2 intensity that overlaps with channel 1\n",
    "   - This asymmetry can reveal important biological relationships between the labeled structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595bed21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
